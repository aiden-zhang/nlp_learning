{"cells":[{"cell_type":"markdown","source":["# 注意:\n","##针对原文件做了修改，删除了原理说明等文字，和插图，仅仅留下关键代码；\n","## 代码已经过colab验证,生成了所有的模型。"],"metadata":{"id":"QbvkYD7t76C6"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29974,"status":"ok","timestamp":1641220377105,"user":{"displayName":"aiden zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00038965460335847869"},"user_tz":-480},"id":"yjN7pPZa2p8c","outputId":"f89b88e7-d08f-4d1d-ab6e-d96e9b09898c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","Collecting transformers\n","  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 17.2 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 17.4 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 19.1 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 569 kB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.15.0\n","Collecting pytorch-crf==0.7.2\n","  Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n","Installing collected packages: pytorch-crf\n","Successfully installed pytorch-crf-0.7.2\n","change to path: /content/gdrive/MyDrive/第二次意图识别_toColab/\n","current path:\n","/content/gdrive/MyDrive/第二次意图识别_toColab\n","ls in current path:\n"," data\t\t\t  textcnn\n"," dataSet.pkl\t\t  textrcnn\n"," model-cnn.h5\t\t  textrnn\n"," model-rcnn.h5\t\t  textrnn+Attention\n"," model-rnn+Attention.h5   TextRNN+Attention.ipynb\n"," model-rnn.h5\t\t  transformerEncoder\n"," parameter.pkl\t\t  意图识别推理及评测.ipynb\n"," runs\t\t\t '第二次进行意图识别(文本分类)-最新版.ipynb'\n"]}],"source":["#colab中运行jupyter文件的步骤：\n","# 1.挂载云盘\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# 2.安装需要的软件\n","!pip3 install transformers\n","!pip3 install pytorch-crf==0.7.2\n","\n","import os\n","def get_root_dir():\n","    if os.path.exists('/content/gdrive/MyDrive/第二次意图识别_toColab/'):\n","        return '/content/gdrive/MyDrive/第二次意图识别_toColab/' #在Colab里\n","    else:\n","        return './' #在本地\n","\n","# 3.调用系统命令，切换到对应工程路径，相当于cd，但是直接!cd是不行的\n","print(\"change to path:\",get_root_dir())\n","os.chdir(get_root_dir())\n","\n","# 4.再次确认路径\n","print('current path:')\n","!pwd\n","print('ls in current path:')\n","!ls\n","\n","# 不借助print()实现多输出结果的打印\n","from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = 'all'\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5299,"status":"ok","timestamp":1641220386510,"user":{"displayName":"aiden zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00038965460335847869"},"user_tz":-480},"id":"mqxfGTkz2jC-","outputId":"06b6fa47-1b57-49fe-dfa4-58fc6963e1da"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda 1.10.0+cu111\n"]}],"source":["# hava a look version\n","import math\n","import torch\n","import torch.nn as nn\n","# import tensorflow as tf\n","# torch.__version__,tf.__version__\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')#torch.device('cpu')#\n","print(device,torch.__version__)\n","# print(device,torch.__version__,tf.__version__)\n","# import tensorflow as tf\n","# import tensorboard\n","# tf.__version__,tensorboard.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":400,"status":"ok","timestamp":1641104678793,"user":{"displayName":"aiden zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00038965460335847869"},"user_tz":-480},"id":"eCR_45Is2jDA","outputId":"800cb895-b410-48c4-f9a4-bf4b9a13614f"},"outputs":[{"name":"stdout","output_type":"stream","text":["rm: cannot remove 'textrnn': No such file or directory\n","rm: cannot remove 'textcnn': No such file or directory\n"]}],"source":["#!rm -r *.pkl textrnn textcnn"]},{"cell_type":"markdown","metadata":{"id":"WbVyyVWd2jDJ"},"source":["# 数据准备"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15688,"status":"ok","timestamp":1641220409688,"user":{"displayName":"aiden zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00038965460335847869"},"user_tz":-480},"id":"KZ5wNWun2jDK","outputId":"8866cbe2-e0fc-4377-e979-b2ac1dda3448"},"outputs":[{"output_type":"stream","name":"stdout","text":["exist!!\n","min_count_word : 1\n","epoch : 20\n","batch_size : 100\n","embedding_dim : 300\n","hidden_size : 128\n","num_layers : 2\n","dropout : 0.5\n","cuda : cuda\n","lr : 0.001\n","num_unknow : 0\n","max_len : 1000\n","d_k : 60\n","d_q : 60\n","d_v : 60\n","d_ff : 1024\n","n_heads : 5\n","n_layers : 2\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 100/306113 [00:09<7:56:27, 10.70it/s]"]},{"output_type":"stream","name":"stdout","text":["\n"," ****************************************************************************************************\n"]},{"output_type":"execute_result","data":{"text/plain":["(torch.Size([10, 40, 300]),\n"," tensor([11,  8,  6, 11, 14, 12,  4,  6,  9, 10], device='cuda:0'))"]},"metadata":{},"execution_count":4}],"source":["import os\n","import time\n","import gensim\n","import random\n","import numpy as np\n","import pickle as pk\n","import pandas as pd\n","from tqdm import tqdm\n","from operator import itemgetter\n","from collections import defaultdict\n","#from sklearn.cross_validation import train_test_split #早已不用\n","from sklearn.model_selection import train_test_split\n","\n","# 准备好模型的参数\n","parameter = {\n","    'min_count_word':1,\n","#     'char2ind':None,\n","#     'ind2char':None,\n","#     'ind2embeding':None,\n","#     'output_size': None,\n","    'epoch':20,\n","    'batch_size':100,\n","    'embedding_dim':300,\n","    'hidden_size':128,\n","    'num_layers':2, #堆叠LSTM的层数，默认值为1\n","    'dropout':0.5,\n","    'cuda':device,\n","    'lr':0.001,\n","    'num_unknow':0,\n","    'max_len':1000,\n","    'd_k':60, #k,q,v的隐层节点数\n","    'd_q':60,\n","    'd_v':60,\n","    'd_ff':1024, #ffn的隐层节点数\n","    'n_heads':5,\n","    'n_layers':2,\n","}\n","\n","def build_dataSet(data,parameter):\n","    # 构建训练集（chars，labels），构建词汇表（char2ind，ind2char）\n","    chars = []\n","    labels = []\n","    vocab = defaultdict(int)\n","    vocab['<pad>'] = parameter['min_count_word']\n","    for text,label in tqdm(zip(data.text,data.label)):\n","        chars.append(text.split())\n","        labels.append(label)\n","        for char in chars[-1]:\n","            vocab[char] += 1\n","    vocab['<unk>'] = parameter['min_count_word']\n","    for char in vocab:\n","        if vocab[char] < parameter['min_count_word']:\n","            del vocab[char]\n","    char2ind,ind2char = dict(zip(vocab.keys(),range(len(vocab)))), \\\n","    dict(zip(range(len(vocab)),vocab.keys()))\n","    ind2embeding = np.random.randn(len(vocab), parameter['embedding_dim']).astype(np.float32) / np.sqrt(len(vocab))\n","    # 加载词向量\n","    w2v = gensim.models.Word2Vec.load('data/wiki/wiki.Mode')\n","    for ind,i in enumerate(char2ind.keys()):\n","        try:\n","            embedding = np.asarray(w2v.wv[i], dtype='float32')\n","            ind2embeding[ind] = embedding\n","        except:\n","            parameter['num_unknow'] += 1\n","    parameter['ind2char'] = ind2char\n","    parameter['char2ind'] = char2ind\n","    parameter['ind2embeding'] = ind2embeding\n","    parameter['output_size'] = len(set(labels))\n","    return np.array(chars),np.array(labels)\n","\n","def batch_yield(chars,labels,parameter,shuffle = True):\n","    for train_epoch in range(parameter['epoch']):\n","        if shuffle:\n","            permutation = np.random.permutation(len(chars))\n","            chars = chars[permutation]\n","            labels = labels[permutation]\n","        max_len = 0\n","        batch_x,batch_y,len_x = [],[],[]\n","        for iters in tqdm(range(len(chars))):\n","            batch_ids = itemgetter(*chars[iters])(parameter['char2ind'])\n","            try:\n","                batch_ids = list(batch_ids)\n","            except:\n","                batch_ids = [batch_ids,0]\n","            if len(batch_ids) > max_len:\n","                max_len = len(batch_ids)\n","            batch_x.append(batch_ids)\n","            batch_y.append(labels[iters])\n","            len_x.append(len(batch_ids))\n","            if len(batch_x) >= parameter['batch_size']:\n","                batch_x = [np.array(list(itemgetter(*x_ids)(parameter['ind2embeding']))+[parameter['ind2embeding'][0]]*(max_len-len(x_ids))) for x_ids in batch_x]\n","                device = parameter['cuda']\n","                yield torch.from_numpy(np.array(batch_x)).to(device),torch.from_numpy(np.array(batch_y)).to(device).long(),len_x,True,None\n","                max_len,batch_x,batch_y,len_x = 0,[],[],[]\n","        batch_x = [np.array(list(itemgetter(*x_ids)(parameter['ind2embeding']))+[parameter['ind2embeding'][0]]*(max_len-len(x_ids))) for x_ids in batch_x]\n","        device = parameter['cuda']\n","        yield torch.from_numpy(np.array(batch_x)).to(device),torch.from_numpy(np.array(batch_y)).to(device).long(),len_x,True,train_epoch\n","        max_len,batch_x,batch_y,len_x = 0,[],[],[]\n","    yield None,None,None,False,None\n","    \n","def batch_yield_predict(chars,parameter):\n","    batch_x,batch_y = [],[]\n","    for iters in range(len(chars)):\n","        if chars[iters] in parameter['char2ind']:\n","            batch_x.append(parameter['ind2embeding'][parameter['char2ind'][chars[iters]]])\n","        else:\n","            batch_x.append(parameter['ind2embeding'][parameter['char2ind']['<unk>']])\n","    batch_x = [batch_x]\n","#     batch_y = [0]\n","    device = parameter['cuda']\n","    return torch.from_numpy(np.array(batch_x)).to(device)#,torch.from_numpy(np.array(batch_y)).to(device).long()\n","\n","if os.path.exists('dataSet.pkl') and os.path.exists('parameter.pkl'):\n","    print('exist!!')\n","    [train_chars,test_chars,train_labels,test_labels] = pk.load(open('dataSet.pkl','rb'))\n","    parameter_copy = pk.load(open('parameter.pkl','rb'))\n","    for i in parameter_copy.keys():\n","        if i not in parameter:\n","            parameter[i] = parameter_copy[i]\n","        else:\n","            print(i,':',parameter[i])\n","    pk.dump(parameter,open('parameter.pkl','wb'))\n","    \n","else:\n","    print('not exist')\n","    data = pd.read_csv('data/classification_data/classification_data.csv')\n","    chars_src,labels_src = build_dataSet(data,parameter)\n","    # 划分训练集和测试集\n","    train_chars,test_chars,train_labels,test_labels = train_test_split(chars_src,labels_src, test_size=0.2, random_state=42)\n","    pk.dump([train_chars,test_chars,train_labels,test_labels],open('dataSet.pkl','wb'))\n","    pk.dump(parameter,open('parameter.pkl','wb'))\n","\n","train_yield = batch_yield(train_chars,train_labels,parameter)\n","seqs,label,x_len,keys,epoch = next(train_yield)\n","# sta = time.time()\n","# while 1:\n","#     a,b,c = next(train_yield)\n","#     if not c:\n","#         break\n","        \n","# print(time.time()-sta)\n","# train_chars\n","seqs,labels,x_len,_,_ = next(train_yield)\n","print('\\n','*'*100)\n","seqs[:10].shape,labels[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1641213411270,"user":{"displayName":"aiden zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00038965460335847869"},"user_tz":-480},"id":"ssZCmPx6kqYI","outputId":"5e82b4f8-3c92-4f52-f673-edaef0e67328"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['min_count_word', 'epoch', 'batch_size', 'embedding_dim', 'hidden_size', 'num_layers', 'dropout', 'cuda', 'lr', 'num_unknow', 'max_len', 'd_k', 'd_q', 'd_v', 'd_ff', 'n_heads', 'n_layers', 'ind2char', 'char2ind', 'ind2embeding', 'output_size'])"]},"metadata":{},"execution_count":5}],"source":["pkl_fd=open('parameter.pkl','rb')\n","data=pk.load(pkl_fd)\n","data.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":519,"status":"ok","timestamp":1641213417152,"user":{"displayName":"aiden zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00038965460335847869"},"user_tz":-480},"id":"4MWAU9vdeK_i","outputId":"388880cb-fa71-478a-af24-3cdcd14e42f1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([100, 41, 300])"]},"metadata":{},"execution_count":6}],"source":["seqs.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s9a_iB7P2jDL","outputId":"70b1ae26-559e-483d-e9fd-11be5a8c6543","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641213419268,"user_tz":-480,"elapsed":4,"user":{"displayName":"aiden zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00038965460335847869"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([100, 41, 300]), 100, 41)"]},"metadata":{},"execution_count":7}],"source":["seqs.shape,len(x_len),max(x_len)"]},{"cell_type":"markdown","metadata":{"id":"ZZHKmhMd2jDL"},"source":["# textCNN"]},{"cell_type":"markdown","metadata":{"id":"9y_9sg2p2jDL"},"source":["## textCNN模型实现"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eokAUCcD2jDL"},"outputs":[],"source":["import torch.nn.functional as F # pytorch 激活函数的类\n","from torch import nn,optim # 构建模型和优化器\n","\n","# 构建分类模型\n","class TextCNN(nn.Module):\n","    def __init__(self, parameter):\n","        super(TextCNN, self).__init__()\n","        filter_size=(3,4,5)\n","        hidden_size = parameter['hidden_size']\n","        embedding_dim = parameter['embedding_dim']\n","        output_size = parameter['output_size']\n","        dropout = parameter['dropout']\n","        \n","        self.convs = nn.ModuleList([nn.Conv2d(1, hidden_size,(k, embedding_dim)) for k in filter_size])\n","        # ins:(batch:100,C:1,len(chars):40,embedding_dim:300)\n","        # covs:(3/4/5,300),kernel = 128\n","        # outs:(batch:100,C:128,40-3/4/5+1,300-300+1)->(100,128,38,1)\n","        self.dropout = nn.Dropout(dropout)\n","        self.fc = nn.Linear(hidden_size * len(filter_size), output_size)\n","\n","    def forward(self, x):\n","        x = x.unsqueeze(1) # [batch, channel, word_num, embedding_dim] = [N,C,H,W] -> (-1, 1, 20, 300)\n","#         x = [F.relu(conv(x)).squeeze(3) for conv in self.convs] # len(filter_size) * (N, filter_num, H) -> 3 * (-1, 100, 18)\n","        x = [F.tanh(conv(x)).squeeze(3) for conv in self.convs] # len(filter_size) * (N, filter_num, H) -> 3 * (-1, 100, 18)\n","#         x = [F.sigmoid(conv(x)).squeeze(3) for conv in self.convs] # len(filter_size) * (N, filter_num, H) -> 3 * (-1, 100, 18)\n","#         x = [F.sigmoid(conv(x)).squeeze(3) for conv in self.convs] # len(filter_size) * (N, filter_num, H) -> 3 * (-1, 100, 18)\n","        out_new = []\n","#         print([i.shape for i in x],'x.shape')\n","        for output in x:\n","            try:\n","                out_new.append(F.max_pool1d(output,output.shape[2].item()).squeeze(2))\n","            except:\n","                out_new.append(F.max_pool1d(output,output.shape[2]).squeeze(2))\n","#         print([i.shape for i in out_new],'out_new.shape')\n","        x = out_new\n","        x = torch.cat(x, 1) # (N, filter_num * len(filter_size)) -> (163, 100 * 3)\n","        x = self.dropout(x)\n","        x = self.fc(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3041,"status":"ok","timestamp":1641213476623,"user":{"displayName":"aiden zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00038965460335847869"},"user_tz":-480},"id":"hIX4MNCh2jDM","outputId":"62cf1ef1-6182-4a18-968c-e95ddf930427"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n"]}],"source":["# 查看网络结构\n","from torch.utils.tensorboard import SummaryWriter\n","x = torch.rand(100,32,300)\n","model = TextCNN(parameter)\n"," \n","with SummaryWriter(comment='textcnn') as w:\n","    w.add_graph(model, x)  "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2250,"status":"ok","timestamp":1641213480954,"user":{"displayName":"aiden zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00038965460335847869"},"user_tz":-480},"id":"yqYhryiH2jDM","outputId":"e72b729c-af8e-49d5-9f08-b6295461541b"},"outputs":[{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 199/306113 [01:19<34:07:26,  2.49it/s]\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"]},{"output_type":"execute_result","data":{"text/plain":["(torch.Size([100, 42, 300]), torch.Size([100, 15]))"]},"metadata":{},"execution_count":11}],"source":["model = TextCNN(parameter).to(parameter['cuda'])\n","train_yield = batch_yield(train_chars,train_labels,parameter)\n","seqs,label,_,keys,epoch = next(train_yield)\n","seqs.shape,model(seqs).shape"]},{"cell_type":"markdown","metadata":{"id":"jw4S54K_2jDM"},"source":["## textCNN模型训练"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":523,"status":"ok","timestamp":1641213483274,"user":{"displayName":"aiden zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00038965460335847869"},"user_tz":-480},"id":"uUKK2oQw2jDN","outputId":"1cdabbe3-a7e0-48e4-d726-07fd48050eb9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["TextCNN(\n","  (convs): ModuleList(\n","    (0): Conv2d(1, 128, kernel_size=(3, 300), stride=(1, 1))\n","    (1): Conv2d(1, 128, kernel_size=(4, 300), stride=(1, 1))\n","    (2): Conv2d(1, 128, kernel_size=(5, 300), stride=(1, 1))\n","  )\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc): Linear(in_features=384, out_features=15, bias=True)\n",")"]},"metadata":{},"execution_count":12},{"output_type":"stream","name":"stdout","text":["TextCNN model has been trainned\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 99/306113 [00:02<2:06:58, 40.17it/s]\n"]}],"source":["import os\n","import shutil\n","import pickle as pk\n","from torch.utils.tensorboard import SummaryWriter\n","\n","# 记录日志\n","shutil.rmtree('textcnn') if os.path.exists('textcnn') else 1\n","writer = SummaryWriter('./textcnn', comment='textcnn')\n","\n","# 构建模型\n","model = TextCNN(parameter).to(parameter['cuda'])\n","\n","\n","# 确定训练模式\n","model.train()\n","\n","# 确定优化器和损失\n","optimizer = torch.optim.SGD(model.parameters(),lr=0.001, momentum=0.95, nesterov=True)\n","# optimizer = torch.optim.Adam(model.parameters(),lr = parameter['lr'], \\\n","#                              weight_decay = 0.01)\n","criterion = nn.CrossEntropyLoss()\n","\n","# # 保存图\n","# train_yield = batch_yield(train_chars,train_labels,parameter)\n","# seqs,label,_,keys,epoch = next(train_yield)\n","# writer.add_graph(model, (seqs,))\n","\n","# 准备迭代器\n","train_yield = batch_yield(train_chars,train_labels,parameter)\n","\n","# 开始训练\n","loss_cal = []\n","min_loss = float('inf')\n","if os.path.exists('model-cnn.h5'):\n","  print('TextCNN model has been trainned')\n","else:\n","  with writer:\n","      while 1:\n","          seqs,label,_,keys,epoch = next(train_yield)\n","          if not keys:\n","              break\n","          out = model(seqs)\n","          loss = criterion(out, label)\n","          optimizer.zero_grad()\n","          loss.backward()\n","          optimizer.step()\n","          loss_cal.append(loss.item())\n","          if epoch is not None:\n","              if (epoch+1)%1 == 0:\n","                  loss_cal = sum(loss_cal)/len(loss_cal)\n","                  if loss_cal < min_loss:\n","                      min_loss = loss_cal\n","                      torch.save(model.state_dict(), 'model-cnn.h5')\n","                  print('epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, \\\n","                                                        parameter['epoch'],loss_cal))\n","              writer.add_scalar('loss',loss_cal,global_step=epoch+1)\n","              loss_cal = [loss.item()]\n","      writer.flush()\n","      writer.close()\n","    \n","# torch.save(model.state_dict(), 'model-cnn.h5')"]},{"cell_type":"markdown","metadata":{"id":"0PqZcjJh2jDO"},"source":["# textRNN"]},{"cell_type":"markdown","metadata":{"id":"ZVNDxE402jDO"},"source":["## textRNN模型实现"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vgdPK8Dm2jDO"},"outputs":[],"source":["import torch.nn.functional as F # pytorch 激活函数的类\n","from torch import nn,optim # 构建模型和优化器\n","\n","# 构建分类模型\n","class TextRNN(nn.Module):\n","    def __init__(self, parameter):\n","        super(TextRNN, self).__init__()\n","        embedding_dim = parameter['embedding_dim']\n","        hidden_size = parameter['hidden_size']\n","        output_size = parameter['output_size']\n","        num_layers = parameter['num_layers']\n","        dropout = parameter['dropout']\n","        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, bidirectional=True, batch_first=True, dropout=dropout)\n","        self.fc = nn.Linear(hidden_size*2, output_size)\n","        \n","    def forward(self, x):\n","#         print(x.shape,'x.shape')\n","        out,(h, c)= self.lstm(x)\n","#         print(out.shape,'out.shape')\n","        out = self.fc(out[:, -1, :])\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1hPUztrM2jDO"},"outputs":[],"source":["from torch.utils.tensorboard import SummaryWriter\n","x = torch.rand(100,32,300)\n","model = TextRNN(parameter)\n"," \n","with SummaryWriter(comment='textrnn') as w:\n","    w.add_graph(model, x)  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SRc2xAVt2jDO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641213513227,"user_tz":-480,"elapsed":525,"user":{"displayName":"aiden zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00038965460335847869"}},"outputId":"7f3b548d-b6c7-4f24-9639-aa781c0d14c0"},"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/306113 [00:00<?, ?it/s]"]},{"output_type":"execute_result","data":{"text/plain":["(torch.Size([100, 40, 300]), torch.Size([100, 15]))"]},"metadata":{},"execution_count":15}],"source":["model = TextRNN(parameter).to(parameter['cuda'])\n","train_yield = batch_yield(train_chars,train_labels,parameter)\n","seqs,label,_,keys,epoch = next(train_yield)\n","seqs.shape,model(seqs).shape"]},{"cell_type":"markdown","metadata":{"id":"784jgc7h2jDP"},"source":["## textRNN模型训练"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_s7Nmsii2jDP","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641216662443,"user_tz":-480,"elapsed":517,"user":{"displayName":"aiden zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00038965460335847869"}},"outputId":"7454e16c-c2aa-499d-dff1-a09b9194d43c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["TextRNN(\n","  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n","  (fc): Linear(in_features=256, out_features=15, bias=True)\n",")"]},"metadata":{},"execution_count":24},{"output_type":"stream","name":"stdout","text":["TextRNN model has been trainned\n"]}],"source":["import os\n","import shutil\n","import pickle as pk\n","from torch.utils.tensorboard import SummaryWriter\n","\n","# 记录日志\n","shutil.rmtree('textrnn') if os.path.exists('textrnn') else 1\n","writer = SummaryWriter('./textrnn', comment='textrnn')\n","\n","# 构建模型\n","model = TextRNN(parameter).to(parameter['cuda'])\n","\n","# 确定训练模式\n","model.train()\n","\n","# 确定优化器和损失\n","optimizer = torch.optim.SGD(model.parameters(),lr=0.1, momentum=0.95, nesterov=True)\n","# optimizer = torch.optim.Adam(model.parameters(),lr = parameter['lr'], \\\n","#                              weight_decay = 0.01)\n","criterion = nn.CrossEntropyLoss()\n","\n","# 保存图\n","# train_yield = batch_yield(train_chars,train_labels,parameter)\n","# seqs,label,_,keys,epoch = next(train_yield)\n","# writer.add_graph(model, (seqs,))\n","\n","# 准备迭代器\n","train_yield = batch_yield(train_chars,train_labels,parameter)\n","\n","# 开始训练\n","loss_cal = []\n","min_loss = float('inf')\n","if os.path.exists('model-rnn.h5'):\n","  print('TextRNN model has been trainned')\n","else:\n","  with writer:\n","      while 1:\n","          seqs,label,_,keys,epoch = next(train_yield)\n","          if not keys:\n","              break\n","          out = model(seqs)\n","          loss = criterion(out, label)\n","          optimizer.zero_grad()\n","          loss.backward()\n","          optimizer.step()\n","          loss_cal.append(loss.item())\n","          if epoch is not None:\n","              if (epoch+1)%1 == 0:\n","                  loss_cal = sum(loss_cal)/len(loss_cal)\n","                  if loss_cal < min_loss:\n","                      min_loss = loss_cal\n","                      torch.save(model.state_dict(), 'model-rnn.h5')\n","                  print('epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, \\\n","                                                        parameter['epoch'],loss_cal))\n","              writer.add_scalar('loss',loss_cal,global_step=epoch+1)\n","              loss_cal = [loss.item()]\n","      writer.flush()\n","      writer.close()\n","    \n","# torch.save(model.state_dict(), 'model-rnn.h5')"]},{"cell_type":"markdown","metadata":{"id":"8KYw1vuR2jDQ"},"source":["# textRCNN"]},{"cell_type":"markdown","metadata":{"id":"RvV_G8Za2jDQ"},"source":["## textRCNN模型实现"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Xc1ltqn2jDQ"},"outputs":[],"source":["import torch.nn.functional as F # pytorch 激活函数的类\n","from torch import nn,optim # 构建模型和优化器\n","\n","class TextRCNN(nn.Module):\n","    def __init__(self, parameter):\n","        super(TextRCNN, self).__init__()\n","        embedding_dim = parameter['embedding_dim']\n","        hidden_size = parameter['hidden_size']\n","        output_size = parameter['output_size']\n","        num_layers = parameter['num_layers']\n","        dropout = parameter['dropout']\n","        self.lstm = nn.LSTM(embedding_dim,hidden_size, \\\n","                            num_layers, bidirectional=True, \\\n","                            batch_first=True, dropout=dropout)\n","        self.dropout = nn.Dropout(dropout)\n","        self.fc = nn.Linear(hidden_size * 2, output_size)\n","        self.fc_for_concat = nn.Linear(hidden_size * 2 + embedding_dim, hidden_size * 2)\n","    \n","    def forward(self, x):\n","        out,(h, c)= self.lstm(x)\n","#         print(out.shape,x.shape)\n","        \n","        out = self.fc_for_concat(torch.cat((x, out), 2))\n","#         print(out.shape)\n","        # 激活函数\n","        out = F.tanh(out)\n","#         print(out.shape)\n","        out = out.permute(0, 2, 1)\n","#         print(out.shape)\n","        try:\n","            out = F.max_pool1d(out, out.size(2).item())\n","        except:\n","            out = F.max_pool1d(out, out.size(2))\n","#         print(out.shape)\n","        out = out.squeeze(-1)\n","        out = self.dropout(out)\n","        out = self.fc(out)\n","        return out\n","    \n","# 查看形状\n","# model = TextRCNN(parameter).to(parameter['cuda'])\n","# a = model(seqs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PcO-sLO62jDQ"},"outputs":[],"source":["from torch.utils.tensorboard import SummaryWriter\n","x = torch.rand(100,32,300)\n","model = TextRCNN(parameter)\n"," \n","with SummaryWriter(comment='textrcnn') as w:\n","    w.add_graph(model, x)  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9PHf1U_F2jDQ","outputId":"c9bd262b-93e1-417a-9b61-1886ad71c294","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641214678778,"user_tz":-480,"elapsed":532,"user":{"displayName":"aiden zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00038965460335847869"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/306113 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"]}],"source":["# parameter['batch_size'] = 50\n","model = TextRCNN(parameter).to(parameter['cuda'])\n","train_yield = batch_yield(train_chars,train_labels,parameter)\n","seqs,label,_,keys,epoch = next(train_yield)\n","# print(seqs.shape)\n","_ = model(seqs)"]},{"cell_type":"markdown","metadata":{"id":"Eq6X7ERN2jDR"},"source":["## textRCNN模型训练"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TZrXWrAz2jDR","outputId":"c2d9c27a-5770-4d2f-bd3b-917ddb26cba8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641215822837,"user_tz":-480,"elapsed":1140087,"user":{"displayName":"aiden zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00038965460335847869"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":22},{"output_type":"execute_result","data":{"text/plain":["TextRCNN(\n","  (lstm): LSTM(300, 128, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc): Linear(in_features=256, out_features=15, bias=True)\n","  (fc_for_concat): Linear(in_features=556, out_features=256, bias=True)\n",")"]},"metadata":{},"execution_count":22},{"output_type":"stream","name":"stderr","text":["\n","  0%|          | 0/306113 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","\n","  0%|          | 99/306113 [00:04<3:42:49, 22.89it/s]\n","\n","  0%|          | 1000/306113 [00:00<01:04, 4751.16it/s]\u001b[A\n","  1%|          | 1600/306113 [00:00<01:01, 4914.20it/s]\u001b[A\n","  1%|          | 2200/306113 [00:00<00:58, 5191.48it/s]\u001b[A\n","  1%|          | 2800/306113 [00:00<00:57, 5314.08it/s]\u001b[A\n","  1%|          | 3400/306113 [00:00<00:57, 5283.26it/s]\u001b[A\n","  1%|▏         | 4000/306113 [00:00<00:56, 5301.23it/s]\u001b[A\n","  2%|▏         | 4600/306113 [00:00<00:56, 5342.72it/s]\u001b[A\n","  2%|▏         | 5200/306113 [00:00<00:56, 5354.79it/s]\u001b[A\n","  2%|▏         | 5800/306113 [00:01<00:54, 5490.30it/s]\u001b[A\n","  2%|▏         | 6400/306113 [00:01<00:55, 5385.75it/s]\u001b[A\n","  2%|▏         | 6940/306113 [00:01<00:56, 5302.05it/s]\u001b[A\n","  2%|▏         | 7500/306113 [00:01<00:57, 5230.40it/s]\u001b[A\n","  3%|▎         | 8100/306113 [00:01<00:56, 5290.18it/s]\u001b[A\n","  3%|▎         | 8700/306113 [00:01<00:55, 5329.15it/s]\u001b[A\n","  3%|▎         | 9300/306113 [00:01<00:55, 5315.32it/s]\u001b[A\n","  3%|▎         | 9900/306113 [00:01<00:56, 5282.04it/s]\u001b[A\n","  3%|▎         | 10429/306113 [00:02<01:02, 4754.61it/s]\u001b[A\n","  4%|▎         | 11000/306113 [00:02<01:00, 4880.15it/s]\u001b[A\n","  4%|▍         | 11600/306113 [00:02<00:57, 5093.23it/s]\u001b[A\n","  4%|▍         | 12200/306113 [00:02<00:56, 5220.06it/s]\u001b[A\n","  4%|▍         | 12800/306113 [00:02<00:56, 5194.45it/s]\u001b[A\n","  4%|▍         | 13400/306113 [00:02<00:56, 5182.50it/s]\u001b[A\n","  5%|▍         | 14000/306113 [00:02<00:56, 5142.22it/s]\u001b[A\n","  5%|▍         | 14600/306113 [00:02<00:56, 5171.10it/s]\u001b[A\n","  5%|▍         | 15200/306113 [00:02<00:55, 5253.00it/s]\u001b[A\n","  5%|▌         | 15800/306113 [00:03<00:54, 5282.80it/s]\u001b[A\n","  5%|▌         | 16400/306113 [00:03<00:54, 5292.82it/s]\u001b[A\n","  6%|▌         | 17000/306113 [00:03<00:54, 5259.73it/s]\u001b[A\n","  6%|▌         | 17527/306113 [00:03<00:54, 5254.99it/s]\u001b[A\n","  6%|▌         | 18100/306113 [00:03<00:54, 5267.26it/s]\u001b[A\n","  6%|▌         | 18700/306113 [00:03<00:52, 5437.83it/s]\u001b[A\n","  6%|▋         | 19300/306113 [00:03<00:52, 5443.39it/s]\u001b[A\n","  7%|▋         | 19900/306113 [00:03<00:52, 5485.26it/s]\u001b[A\n","  7%|▋         | 20500/306113 [00:03<00:52, 5451.81it/s]\u001b[A\n","  7%|▋         | 21046/306113 [00:04<00:52, 5386.51it/s]\u001b[A\n","  7%|▋         | 21585/306113 [00:04<00:53, 5356.30it/s]\u001b[A\n","  7%|▋         | 22121/306113 [00:04<00:55, 5107.10it/s]\u001b[A\n","  7%|▋         | 22700/306113 [00:04<00:54, 5156.94it/s]\u001b[A\n","  8%|▊         | 23300/306113 [00:04<00:53, 5240.60it/s]\u001b[A\n","  8%|▊         | 23900/306113 [00:04<00:53, 5317.10it/s]\u001b[A\n","  8%|▊         | 24433/306113 [00:04<00:53, 5246.37it/s]\u001b[A\n","  8%|▊         | 25000/306113 [00:04<00:54, 5171.02it/s]\u001b[A\n","  8%|▊         | 25600/306113 [00:04<00:52, 5301.04it/s]\u001b[A\n","  9%|▊         | 26200/306113 [00:04<00:52, 5305.57it/s]\u001b[A\n","  9%|▉         | 26800/306113 [00:05<00:51, 5394.58it/s]\u001b[A\n","  9%|▉         | 27400/306113 [00:05<00:51, 5428.91it/s]\u001b[A\n","  9%|▉         | 28000/306113 [00:05<00:51, 5380.22it/s]\u001b[A\n","  9%|▉         | 28539/306113 [00:05<00:51, 5378.22it/s]\u001b[A\n"," 10%|▉         | 29100/306113 [00:05<00:52, 5294.80it/s]\u001b[A\n"," 10%|▉         | 29700/306113 [00:05<00:52, 5278.98it/s]\u001b[A\n"," 10%|▉         | 30229/306113 [00:05<00:52, 5278.83it/s]\u001b[A\n"," 10%|█         | 30800/306113 [00:05<00:52, 5245.12it/s]\u001b[A\n"," 10%|█         | 31400/306113 [00:05<00:52, 5232.94it/s]\u001b[A\n"," 10%|█         | 32000/306113 [00:06<00:51, 5307.02it/s]\u001b[A\n"," 11%|█         | 32531/306113 [00:06<00:52, 5162.86it/s]\u001b[A\n"," 11%|█         | 33100/306113 [00:06<00:53, 5089.40it/s]\u001b[A\n"," 11%|█         | 33700/306113 [00:06<00:52, 5172.31it/s]\u001b[A\n"," 11%|█         | 34300/306113 [00:06<00:52, 5162.09it/s]\u001b[A\n"," 11%|█▏        | 34900/306113 [00:06<00:52, 5200.12it/s]\u001b[A\n"," 12%|█▏        | 35421/306113 [00:06<00:52, 5140.77it/s]\u001b[A\n"," 12%|█▏        | 36000/306113 [00:06<00:53, 5084.70it/s]\u001b[A\n"," 12%|█▏        | 36509/306113 [00:06<00:53, 5057.22it/s]\u001b[A\n"," 12%|█▏        | 37015/306113 [00:07<00:53, 5047.94it/s]\u001b[A\n"," 12%|█▏        | 37600/306113 [00:07<00:53, 5049.76it/s]\u001b[A\n"," 12%|█▏        | 38200/306113 [00:07<00:53, 5051.58it/s]\u001b[A\n"," 13%|█▎        | 38706/306113 [00:07<00:53, 5037.90it/s]\u001b[A\n"," 13%|█▎        | 39210/306113 [00:07<00:53, 4952.32it/s]\u001b[A\n"," 13%|█▎        | 39800/306113 [00:07<00:53, 4951.47it/s]\u001b[A\n"," 13%|█▎        | 40400/306113 [00:07<00:52, 5028.25it/s]\u001b[A\n"," 13%|█▎        | 40903/306113 [00:07<00:52, 5026.03it/s]\u001b[A\n"," 14%|█▎        | 41500/306113 [00:07<00:52, 5049.57it/s]\u001b[A\n"," 14%|█▍        | 42100/306113 [00:08<00:50, 5182.61it/s]\u001b[A\n"," 14%|█▍        | 42700/306113 [00:08<00:50, 5232.42it/s]\u001b[A\n"," 14%|█▍        | 43300/306113 [00:08<00:50, 5238.96it/s]\u001b[A\n"," 14%|█▍        | 43900/306113 [00:08<00:50, 5203.75it/s]\u001b[A\n"," 15%|█▍        | 44500/306113 [00:08<00:49, 5327.25it/s]\u001b[A\n"," 15%|█▍        | 45100/306113 [00:08<00:48, 5388.31it/s]\u001b[A\n"," 15%|█▍        | 45700/306113 [00:08<00:48, 5378.07it/s]\u001b[A\n"," 15%|█▌        | 46300/306113 [00:08<00:48, 5371.66it/s]\u001b[A\n"," 15%|█▌        | 46900/306113 [00:08<00:49, 5241.72it/s]\u001b[A\n"," 15%|█▌        | 47426/306113 [00:09<00:49, 5224.73it/s]\u001b[A\n"," 16%|█▌        | 48000/306113 [00:09<00:48, 5278.16it/s]\u001b[A\n"," 16%|█▌        | 48600/306113 [00:09<00:48, 5325.94it/s]\u001b[A\n"," 16%|█▌        | 49200/306113 [00:09<00:48, 5286.45it/s]\u001b[A\n"," 16%|█▋        | 49800/306113 [00:09<00:47, 5413.72it/s]\u001b[A\n"," 16%|█▋        | 50400/306113 [00:09<00:47, 5439.82it/s]\u001b[A\n"," 17%|█▋        | 51000/306113 [00:09<00:47, 5409.33it/s]\u001b[A\n"," 17%|█▋        | 51600/306113 [00:09<00:47, 5389.32it/s]\u001b[A\n"," 17%|█▋        | 52200/306113 [00:09<00:46, 5462.04it/s]\u001b[A\n"," 17%|█▋        | 52800/306113 [00:10<00:46, 5441.89it/s]\u001b[A\n"," 17%|█▋        | 53400/306113 [00:10<00:47, 5321.92it/s]\u001b[A\n"," 18%|█▊        | 54000/306113 [00:10<00:47, 5292.84it/s]\u001b[A\n"," 18%|█▊        | 54530/306113 [00:10<00:48, 5222.27it/s]\u001b[A\n"," 18%|█▊        | 55100/306113 [00:10<00:48, 5188.90it/s]\u001b[A\n"," 18%|█▊        | 55700/306113 [00:10<00:47, 5259.69it/s]\u001b[A\n"," 18%|█▊        | 56300/306113 [00:10<00:47, 5259.11it/s]\u001b[A\n"," 19%|█▊        | 56900/306113 [00:10<00:46, 5347.46it/s]\u001b[A\n"," 19%|█▉        | 57500/306113 [00:10<00:47, 5282.60it/s]\u001b[A\n"," 19%|█▉        | 58029/306113 [00:11<00:47, 5226.10it/s]\u001b[A\n"," 19%|█▉        | 58552/306113 [00:11<00:48, 5107.18it/s]\u001b[A\n"," 19%|█▉        | 59100/306113 [00:11<00:48, 5106.21it/s]\u001b[A\n"," 20%|█▉        | 59700/306113 [00:11<00:46, 5267.82it/s]\u001b[A\n"," 20%|█▉        | 60228/306113 [00:11<00:46, 5255.94it/s]\u001b[A\n"," 20%|█▉        | 60800/306113 [00:11<00:47, 5127.00it/s]\u001b[A\n"," 20%|██        | 61400/306113 [00:11<00:47, 5164.91it/s]\u001b[A\n"," 20%|██        | 62000/306113 [00:11<00:46, 5268.36it/s]\u001b[A\n"," 20%|██        | 62600/306113 [00:11<00:46, 5282.74it/s]\u001b[A\n"," 21%|██        | 63200/306113 [00:12<00:45, 5308.44it/s]\u001b[A\n"," 21%|██        | 63800/306113 [00:12<00:45, 5291.28it/s]\u001b[A\n"," 21%|██        | 64400/306113 [00:12<00:45, 5349.20it/s]\u001b[A\n"," 21%|██        | 65000/306113 [00:12<00:45, 5298.89it/s]\u001b[A\n"," 21%|██▏       | 65600/306113 [00:12<00:45, 5293.73it/s]\u001b[A\n"," 22%|██▏       | 66200/306113 [00:12<00:45, 5268.99it/s]\u001b[A\n"," 22%|██▏       | 66800/306113 [00:12<00:45, 5249.24it/s]\u001b[A\n"," 22%|██▏       | 67400/306113 [00:12<00:45, 5220.50it/s]\u001b[A\n"," 22%|██▏       | 68000/306113 [00:12<00:45, 5258.95it/s]\u001b[A\n"," 22%|██▏       | 68527/306113 [00:13<00:48, 4884.69it/s]\u001b[A\n"," 23%|██▎       | 69100/306113 [00:13<00:48, 4894.21it/s]\u001b[A\n"," 23%|██▎       | 69700/306113 [00:13<00:46, 5048.08it/s]\u001b[A\n"," 23%|██▎       | 70300/306113 [00:13<00:46, 5044.16it/s]\u001b[A\n"," 23%|██▎       | 70900/306113 [00:13<00:45, 5197.99it/s]\u001b[A\n"," 23%|██▎       | 71500/306113 [00:13<00:44, 5237.45it/s]\u001b[A\n"," 24%|██▎       | 72100/306113 [00:13<00:44, 5234.27it/s]\u001b[A\n"," 24%|██▎       | 72700/306113 [00:13<00:44, 5243.57it/s]\u001b[A\n"," 24%|██▍       | 73300/306113 [00:14<00:43, 5310.84it/s]\u001b[A\n"," 24%|██▍       | 73900/306113 [00:14<00:43, 5356.95it/s]\u001b[A\n"," 24%|██▍       | 74500/306113 [00:14<00:43, 5369.25it/s]\u001b[A\n"," 25%|██▍       | 75100/306113 [00:14<00:42, 5402.03it/s]\u001b[A\n"," 25%|██▍       | 75641/306113 [00:14<00:42, 5379.47it/s]\u001b[A\n"," 25%|██▍       | 76200/306113 [00:14<00:44, 5219.13it/s]\u001b[A\n"," 25%|██▌       | 76800/306113 [00:14<00:43, 5259.64it/s]\u001b[A\n"," 25%|██▌       | 77400/306113 [00:14<00:43, 5264.04it/s]\u001b[A\n"," 25%|██▌       | 78000/306113 [00:14<00:43, 5226.29it/s]\u001b[A\n"," 26%|██▌       | 78600/306113 [00:15<00:42, 5295.35it/s]\u001b[A\n"," 26%|██▌       | 79200/306113 [00:15<00:42, 5366.96it/s]\u001b[A\n"," 26%|██▌       | 79800/306113 [00:15<00:42, 5342.50it/s]\u001b[A\n"," 26%|██▌       | 80335/306113 [00:15<00:43, 5226.89it/s]\u001b[A\n"," 26%|██▋       | 80900/306113 [00:15<00:43, 5203.95it/s]\u001b[A\n"," 27%|██▋       | 81500/306113 [00:15<00:42, 5327.03it/s]\u001b[A\n"," 27%|██▋       | 82033/306113 [00:15<00:42, 5296.28it/s]\u001b[A\n"," 27%|██▋       | 82600/306113 [00:15<00:42, 5272.71it/s]\u001b[A\n"," 27%|██▋       | 83200/306113 [00:15<00:42, 5247.87it/s]\u001b[A\n"," 27%|██▋       | 83800/306113 [00:15<00:41, 5360.46it/s]\u001b[A\n"," 28%|██▊       | 84400/306113 [00:16<00:41, 5321.78it/s]\u001b[A\n"," 28%|██▊       | 85000/306113 [00:16<00:41, 5379.66it/s]\u001b[A\n"," 28%|██▊       | 85600/306113 [00:16<00:39, 5522.34it/s]\u001b[A\n"," 28%|██▊       | 86154/306113 [00:16<00:41, 5246.26it/s]\u001b[A\n"," 28%|██▊       | 86700/306113 [00:16<00:42, 5128.79it/s]\u001b[A\n"," 29%|██▊       | 87300/306113 [00:16<00:41, 5302.64it/s]\u001b[A\n"," 29%|██▊       | 87900/306113 [00:16<00:40, 5336.41it/s]\u001b[A\n"," 29%|██▉       | 88436/306113 [00:16<00:41, 5266.91it/s]\u001b[A\n"," 29%|██▉       | 89000/306113 [00:16<00:41, 5264.41it/s]\u001b[A\n"," 29%|██▉       | 89527/306113 [00:17<00:41, 5255.85it/s]\u001b[A\n"," 29%|██▉       | 90053/306113 [00:17<00:41, 5208.02it/s]\u001b[A\n"," 30%|██▉       | 90584/306113 [00:17<00:41, 5237.48it/s]\u001b[A\n"," 30%|██▉       | 91108/306113 [00:17<00:41, 5123.00it/s]\u001b[A\n"," 30%|██▉       | 91700/306113 [00:17<00:41, 5114.51it/s]\u001b[A\n"," 30%|███       | 92300/306113 [00:17<00:40, 5320.46it/s]\u001b[A\n"," 30%|███       | 92834/306113 [00:17<00:40, 5246.39it/s]\u001b[A\n"," 31%|███       | 93400/306113 [00:17<00:41, 5135.93it/s]\u001b[A\n"," 31%|███       | 94000/306113 [00:17<00:40, 5249.81it/s]\u001b[A\n"," 31%|███       | 94600/306113 [00:18<00:40, 5182.24it/s]\u001b[A\n"," 31%|███       | 95200/306113 [00:18<00:40, 5165.99it/s]\u001b[A\n"," 31%|███▏      | 95800/306113 [00:18<00:40, 5138.77it/s]\u001b[A\n"," 31%|███▏      | 96315/306113 [00:18<00:41, 5094.99it/s]\u001b[A\n"," 32%|███▏      | 96900/306113 [00:18<00:41, 5061.23it/s]\u001b[A\n"," 32%|███▏      | 97500/306113 [00:18<00:41, 5085.32it/s]\u001b[A\n"," 32%|███▏      | 98100/306113 [00:18<00:39, 5201.94it/s]\u001b[A\n"," 32%|███▏      | 98700/306113 [00:18<00:38, 5321.70it/s]\u001b[A\n"," 32%|███▏      | 99300/306113 [00:18<00:39, 5271.14it/s]\u001b[A\n"," 33%|███▎      | 99900/306113 [00:19<00:38, 5315.99it/s]\u001b[A\n"," 33%|███▎      | 100500/306113 [00:19<00:39, 5255.56it/s]\u001b[A\n"," 33%|███▎      | 101028/306113 [00:19<00:38, 5262.17it/s]\u001b[A\n"," 33%|███▎      | 101600/306113 [00:19<00:39, 5150.05it/s]\u001b[A\n"," 33%|███▎      | 102116/306113 [00:19<00:39, 5151.77it/s]\u001b[A\n"," 34%|███▎      | 102700/306113 [00:19<00:39, 5174.60it/s]\u001b[A\n"," 34%|███▎      | 103300/306113 [00:19<00:38, 5211.69it/s]\u001b[A\n"," 34%|███▍      | 103900/306113 [00:19<00:37, 5376.88it/s]\u001b[A\n"," 34%|███▍      | 104500/306113 [00:19<00:37, 5433.88it/s]\u001b[A\n"," 34%|███▍      | 105100/306113 [00:20<00:37, 5334.44it/s]\u001b[A\n"," 35%|███▍      | 105700/306113 [00:20<00:37, 5388.77it/s]\u001b[A\n"," 35%|███▍      | 106300/306113 [00:20<00:37, 5337.50it/s]\u001b[A\n"," 35%|███▍      | 106900/306113 [00:20<00:37, 5340.99it/s]\u001b[A\n"," 35%|███▌      | 107500/306113 [00:20<00:37, 5300.41it/s]\u001b[A\n"," 35%|███▌      | 108100/306113 [00:20<00:37, 5276.43it/s]\u001b[A\n"," 36%|███▌      | 108700/306113 [00:20<00:37, 5257.48it/s]\u001b[A\n"," 36%|███▌      | 109300/306113 [00:20<00:37, 5303.99it/s]\u001b[A\n"," 36%|███▌      | 109900/306113 [00:20<00:36, 5320.85it/s]\u001b[A\n"," 36%|███▌      | 110433/306113 [00:21<00:37, 5264.58it/s]\u001b[A\n"," 36%|███▋      | 111000/306113 [00:21<00:37, 5245.77it/s]\u001b[A\n"," 36%|███▋      | 111525/306113 [00:21<00:37, 5238.40it/s]\u001b[A\n"," 37%|███▋      | 112064/306113 [00:21<00:36, 5281.64it/s]\u001b[A\n"," 37%|███▋      | 112600/306113 [00:21<00:38, 5086.06it/s]\u001b[A\n"," 37%|███▋      | 113200/306113 [00:21<00:37, 5136.92it/s]\u001b[A\n"," 37%|███▋      | 113800/306113 [00:21<00:37, 5110.45it/s]\u001b[A\n"," 37%|███▋      | 114400/306113 [00:21<00:36, 5198.31it/s]\u001b[A\n"," 38%|███▊      | 115000/306113 [00:21<00:36, 5267.94it/s]\u001b[A\n"," 38%|███▊      | 115528/306113 [00:22<00:36, 5271.03it/s]\u001b[A\n"," 38%|███▊      | 116056/306113 [00:22<00:36, 5213.03it/s]\u001b[A\n"," 38%|███▊      | 116578/306113 [00:22<00:36, 5210.82it/s]\u001b[A\n"," 38%|███▊      | 117100/306113 [00:22<00:37, 4977.38it/s]\u001b[A\n"," 38%|███▊      | 117600/306113 [00:22<00:37, 4963.69it/s]\u001b[A\n"," 39%|███▊      | 118200/306113 [00:22<00:37, 5064.16it/s]\u001b[A\n"," 39%|███▉      | 118800/306113 [00:22<00:36, 5136.90it/s]\u001b[A\n"," 39%|███▉      | 119400/306113 [00:22<00:35, 5282.09it/s]\u001b[A\n"," 39%|███▉      | 120000/306113 [00:22<00:34, 5388.20it/s]\u001b[A\n"," 39%|███▉      | 120600/306113 [00:23<00:34, 5403.54it/s]\u001b[A\n"," 40%|███▉      | 121141/306113 [00:23<00:34, 5386.99it/s]\u001b[A\n"," 40%|███▉      | 121700/306113 [00:23<00:35, 5204.21it/s]\u001b[A\n"," 40%|███▉      | 122222/306113 [00:23<00:35, 5207.48it/s]\u001b[A\n"," 40%|████      | 122800/306113 [00:23<00:35, 5167.83it/s]\u001b[A\n"," 40%|████      | 123318/306113 [00:23<00:39, 4588.73it/s]\u001b[A\n"," 40%|████      | 123900/306113 [00:23<00:38, 4744.01it/s]\u001b[A\n"," 41%|████      | 124500/306113 [00:23<00:36, 4966.40it/s]\u001b[A\n"," 41%|████      | 125004/306113 [00:23<00:36, 4937.60it/s]\u001b[A\n"," 41%|████      | 125503/306113 [00:24<00:36, 4935.02it/s]\u001b[A\n"," 41%|████      | 126000/306113 [00:24<00:36, 4919.29it/s]\u001b[A\n"," 41%|████▏     | 126500/306113 [00:24<00:36, 4923.94it/s]\u001b[A\n"," 42%|████▏     | 127100/306113 [00:24<00:35, 4991.15it/s]\u001b[A\n"," 42%|████▏     | 127700/306113 [00:24<00:35, 5044.58it/s]\u001b[A\n"," 42%|████▏     | 128300/306113 [00:24<00:34, 5193.89it/s]\u001b[A\n"," 42%|████▏     | 128900/306113 [00:24<00:33, 5225.26it/s]\u001b[A\n"," 42%|████▏     | 129500/306113 [00:24<00:33, 5250.67it/s]\u001b[A\n"," 43%|████▎     | 130100/306113 [00:24<00:32, 5366.81it/s]\u001b[A\n"," 43%|████▎     | 130700/306113 [00:24<00:32, 5446.85it/s]\u001b[A\n"," 43%|████▎     | 131300/306113 [00:25<00:31, 5481.28it/s]\u001b[A\n"," 43%|████▎     | 131900/306113 [00:25<00:31, 5472.08it/s]\u001b[A\n"," 43%|████▎     | 132500/306113 [00:25<00:32, 5416.71it/s]\u001b[A\n"," 43%|████▎     | 133100/306113 [00:25<00:31, 5449.31it/s]\u001b[A\n"," 44%|████▎     | 133646/306113 [00:25<00:32, 5320.54it/s]\u001b[A\n"," 44%|████▍     | 134200/306113 [00:25<00:32, 5228.07it/s]\u001b[A\n"," 44%|████▍     | 134800/306113 [00:25<00:32, 5219.33it/s]\u001b[A\n"," 44%|████▍     | 135400/306113 [00:25<00:32, 5248.45it/s]\u001b[A\n"," 44%|████▍     | 136000/306113 [00:25<00:32, 5304.89it/s]\u001b[A\n"," 45%|████▍     | 136531/306113 [00:26<00:32, 5249.19it/s]\u001b[A\n"," 45%|████▍     | 137100/306113 [00:26<00:32, 5131.47it/s]\u001b[A\n"," 45%|████▍     | 137700/306113 [00:26<00:32, 5172.59it/s]\u001b[A\n"," 45%|████▌     | 138300/306113 [00:26<00:31, 5341.17it/s]\u001b[A\n"," 45%|████▌     | 138900/306113 [00:26<00:31, 5300.34it/s]\u001b[A\n"," 46%|████▌     | 139431/306113 [00:26<00:34, 4888.77it/s]\u001b[A\n"," 46%|████▌     | 139925/306113 [00:26<00:33, 4896.24it/s]\u001b[A\n"," 46%|████▌     | 140500/306113 [00:26<00:33, 4891.95it/s]\u001b[A\n"," 46%|████▌     | 141100/306113 [00:27<00:32, 5053.17it/s]\u001b[A\n"," 46%|████▋     | 141608/306113 [00:27<00:32, 5041.39it/s]\u001b[A\n"," 46%|████▋     | 142200/306113 [00:27<00:32, 5073.71it/s]\u001b[A\n"," 47%|████▋     | 142800/306113 [00:27<00:31, 5124.73it/s]\u001b[A\n"," 47%|████▋     | 143400/306113 [00:27<00:31, 5154.82it/s]\u001b[A\n"," 47%|████▋     | 144000/306113 [00:27<00:31, 5213.04it/s]\u001b[A\n"," 47%|████▋     | 144600/306113 [00:27<00:30, 5249.70it/s]\u001b[A\n"," 47%|████▋     | 145200/306113 [00:27<00:30, 5225.06it/s]\u001b[A\n"," 48%|████▊     | 145723/306113 [00:27<00:34, 4708.38it/s]\u001b[A\n"," 48%|████▊     | 146300/306113 [00:28<00:32, 4876.86it/s]\u001b[A\n"," 48%|████▊     | 146800/306113 [00:28<00:32, 4900.42it/s]\u001b[A\n"," 48%|████▊     | 147400/306113 [00:28<00:31, 4987.13it/s]\u001b[A\n"," 48%|████▊     | 148000/306113 [00:28<00:31, 5030.00it/s]\u001b[A\n"," 49%|████▊     | 148600/306113 [00:28<00:30, 5102.73it/s]\u001b[A\n"," 49%|████▊     | 149112/306113 [00:28<00:31, 5012.56it/s]\u001b[A\n"," 49%|████▉     | 149614/306113 [00:28<00:31, 5013.00it/s]\u001b[A\n"," 49%|████▉     | 150200/306113 [00:28<00:30, 5095.81it/s]\u001b[A\n"," 49%|████▉     | 150800/306113 [00:28<00:30, 5166.78it/s]\u001b[A\n"," 49%|████▉     | 151400/306113 [00:29<00:29, 5220.05it/s]\u001b[A\n"," 50%|████▉     | 152000/306113 [00:29<00:29, 5216.61it/s]\u001b[A\n"," 50%|████▉     | 152600/306113 [00:29<00:28, 5302.80it/s]\u001b[A\n"," 50%|█████     | 153131/306113 [00:29<00:29, 5227.44it/s]\u001b[A\n"," 50%|█████     | 153700/306113 [00:29<00:29, 5178.77it/s]\u001b[A\n"," 50%|█████     | 154300/306113 [00:29<00:28, 5264.72it/s]\u001b[A\n"," 51%|█████     | 154900/306113 [00:29<00:28, 5344.62it/s]\u001b[A\n"," 51%|█████     | 155500/306113 [00:29<00:28, 5305.38it/s]\u001b[A\n"," 51%|█████     | 156100/306113 [00:29<00:27, 5417.95it/s]\u001b[A\n"," 51%|█████     | 156643/306113 [00:30<00:27, 5407.06it/s]\u001b[A\n"," 51%|█████▏    | 157200/306113 [00:30<00:28, 5207.01it/s]\u001b[A\n"," 52%|█████▏    | 157800/306113 [00:30<00:28, 5175.05it/s]\u001b[A\n"," 52%|█████▏    | 158400/306113 [00:30<00:28, 5248.59it/s]\u001b[A\n"," 52%|█████▏    | 159000/306113 [00:30<00:27, 5267.92it/s]\u001b[A\n"," 52%|█████▏    | 159600/306113 [00:30<00:27, 5261.72it/s]\u001b[A\n"," 52%|█████▏    | 160200/306113 [00:30<00:27, 5289.73it/s]\u001b[A\n"," 53%|█████▎    | 160800/306113 [00:30<00:27, 5290.78it/s]\u001b[A\n"," 53%|█████▎    | 161400/306113 [00:30<00:27, 5309.88it/s]\u001b[A\n"," 53%|█████▎    | 162000/306113 [00:31<00:26, 5341.60it/s]\u001b[A\n"," 53%|█████▎    | 162600/306113 [00:31<00:27, 5310.42it/s]\u001b[A\n"," 53%|█████▎    | 163200/306113 [00:31<00:26, 5326.58it/s]\u001b[A\n"," 54%|█████▎    | 163800/306113 [00:31<00:26, 5343.26it/s]\u001b[A\n"," 54%|█████▎    | 164400/306113 [00:31<00:26, 5324.45it/s]\u001b[A\n"," 54%|█████▍    | 164933/306113 [00:31<00:27, 5167.10it/s]\u001b[A\n"," 54%|█████▍    | 165450/306113 [00:31<00:27, 5132.24it/s]\u001b[A\n"," 54%|█████▍    | 166000/306113 [00:31<00:27, 5080.65it/s]\u001b[A\n"," 54%|█████▍    | 166600/306113 [00:31<00:27, 5092.75it/s]\u001b[A\n"," 55%|█████▍    | 167200/306113 [00:32<00:26, 5172.91it/s]\u001b[A\n"," 55%|█████▍    | 167800/306113 [00:32<00:26, 5291.14it/s]\u001b[A\n"," 55%|█████▌    | 168400/306113 [00:32<00:26, 5224.08it/s]\u001b[A\n"," 55%|█████▌    | 169000/306113 [00:32<00:26, 5197.79it/s]\u001b[A\n"," 55%|█████▌    | 169600/306113 [00:32<00:25, 5273.43it/s]\u001b[A\n"," 56%|█████▌    | 170128/306113 [00:32<00:25, 5272.92it/s]\u001b[A\n"," 56%|█████▌    | 170700/306113 [00:32<00:25, 5276.04it/s]\u001b[A\n"," 56%|█████▌    | 171300/306113 [00:32<00:25, 5232.43it/s]\u001b[A\n"," 56%|█████▌    | 171824/306113 [00:32<00:26, 5148.55it/s]\u001b[A\n"," 56%|█████▋    | 172400/306113 [00:33<00:26, 5119.94it/s]\u001b[A\n"," 57%|█████▋    | 173000/306113 [00:33<00:25, 5211.57it/s]\u001b[A\n"," 57%|█████▋    | 173600/306113 [00:33<00:25, 5192.23it/s]\u001b[A\n"," 57%|█████▋    | 174200/306113 [00:33<00:25, 5213.79it/s]\u001b[A\n"," 57%|█████▋    | 174800/306113 [00:33<00:25, 5224.85it/s]\u001b[A\n"," 57%|█████▋    | 175323/306113 [00:33<00:25, 5155.97it/s]\u001b[A\n"," 57%|█████▋    | 175839/306113 [00:33<00:25, 5137.24it/s]\u001b[A\n"," 58%|█████▊    | 176400/306113 [00:33<00:25, 5172.10it/s]\u001b[A\n"," 58%|█████▊    | 177000/306113 [00:33<00:24, 5342.15it/s]\u001b[A\n"," 58%|█████▊    | 177600/306113 [00:34<00:23, 5370.77it/s]\u001b[A\n"," 58%|█████▊    | 178200/306113 [00:34<00:23, 5354.38it/s]\u001b[A\n"," 58%|█████▊    | 178800/306113 [00:34<00:24, 5240.93it/s]\u001b[A\n"," 59%|█████▊    | 179400/306113 [00:34<00:24, 5258.26it/s]\u001b[A\n"," 59%|█████▉    | 179927/306113 [00:34<00:24, 5241.89it/s]\u001b[A\n"," 59%|█████▉    | 180500/306113 [00:34<00:23, 5345.97it/s]\u001b[A\n"," 59%|█████▉    | 181100/306113 [00:34<00:23, 5292.88it/s]\u001b[A\n"," 59%|█████▉    | 181700/306113 [00:34<00:23, 5280.14it/s]\u001b[A\n"," 60%|█████▉    | 182300/306113 [00:34<00:23, 5350.38it/s]\u001b[A\n"," 60%|█████▉    | 182900/306113 [00:35<00:23, 5331.84it/s]\u001b[A\n"," 60%|█████▉    | 183500/306113 [00:35<00:23, 5280.63it/s]\u001b[A\n"," 60%|██████    | 184100/306113 [00:35<00:22, 5324.83it/s]\u001b[A\n"," 60%|██████    | 184700/306113 [00:35<00:23, 5254.15it/s]\u001b[A\n"," 61%|██████    | 185300/306113 [00:35<00:23, 5230.86it/s]\u001b[A\n"," 61%|██████    | 185900/306113 [00:35<00:22, 5263.58it/s]\u001b[A\n"," 61%|██████    | 186500/306113 [00:35<00:22, 5291.90it/s]\u001b[A\n"," 61%|██████    | 187100/306113 [00:35<00:22, 5265.93it/s]\u001b[A\n"," 61%|██████▏   | 187700/306113 [00:35<00:22, 5255.59it/s]\u001b[A\n"," 62%|██████▏   | 188300/306113 [00:36<00:22, 5352.94it/s]\u001b[A\n"," 62%|██████▏   | 188900/306113 [00:36<00:21, 5357.45it/s]\u001b[A\n"," 62%|██████▏   | 189437/306113 [00:36<00:21, 5346.24it/s]\u001b[A\n"," 62%|██████▏   | 190000/306113 [00:36<00:22, 5267.70it/s]\u001b[A\n"," 62%|██████▏   | 190600/306113 [00:36<00:21, 5268.10it/s]\u001b[A\n"," 62%|██████▏   | 191200/306113 [00:36<00:21, 5317.49it/s]\u001b[A\n"," 63%|██████▎   | 191732/306113 [00:36<00:21, 5248.94it/s]\u001b[A\n"," 63%|██████▎   | 192300/306113 [00:36<00:21, 5213.63it/s]\u001b[A\n"," 63%|██████▎   | 192900/306113 [00:36<00:21, 5165.91it/s]\u001b[A\n"," 63%|██████▎   | 193500/306113 [00:37<00:21, 5245.39it/s]\u001b[A\n"," 63%|██████▎   | 194100/306113 [00:37<00:21, 5224.75it/s]\u001b[A\n"," 64%|██████▎   | 194700/306113 [00:37<00:21, 5170.25it/s]\u001b[A\n"," 64%|██████▍   | 195300/306113 [00:37<00:21, 5141.85it/s]\u001b[A\n"," 64%|██████▍   | 195900/306113 [00:37<00:21, 5228.05it/s]\u001b[A\n"," 64%|██████▍   | 196500/306113 [00:37<00:21, 5174.14it/s]\u001b[A\n"," 64%|██████▍   | 197100/306113 [00:37<00:20, 5333.09it/s]\u001b[A\n"," 65%|██████▍   | 197700/306113 [00:37<00:20, 5363.33it/s]\u001b[A\n"," 65%|██████▍   | 198300/306113 [00:37<00:19, 5427.73it/s]\u001b[A\n"," 65%|██████▍   | 198844/306113 [00:38<00:19, 5371.76it/s]\u001b[A\n"," 65%|██████▌   | 199382/306113 [00:38<00:20, 5208.87it/s]\u001b[A\n"," 65%|██████▌   | 199904/306113 [00:38<00:21, 4910.56it/s]\u001b[A\n"," 65%|██████▌   | 200500/306113 [00:38<00:20, 5085.42it/s]\u001b[A\n"," 66%|██████▌   | 201100/306113 [00:38<00:20, 5170.38it/s]\u001b[A\n"," 66%|██████▌   | 201700/306113 [00:38<00:19, 5254.26it/s]\u001b[A\n"," 66%|██████▌   | 202300/306113 [00:38<00:19, 5236.78it/s]\u001b[A\n"," 66%|██████▋   | 202900/306113 [00:38<00:19, 5240.06it/s]\u001b[A\n"," 66%|██████▋   | 203500/306113 [00:38<00:19, 5221.80it/s]\u001b[A\n"," 67%|██████▋   | 204100/306113 [00:39<00:19, 5256.85it/s]\u001b[A\n"," 67%|██████▋   | 204700/306113 [00:39<00:19, 5225.55it/s]\u001b[A\n"," 67%|██████▋   | 205300/306113 [00:39<00:19, 5225.10it/s]\u001b[A\n"," 67%|██████▋   | 205823/306113 [00:39<00:19, 5181.42it/s]\u001b[A\n"," 67%|██████▋   | 206400/306113 [00:39<00:19, 5235.26it/s]\u001b[A\n"," 68%|██████▊   | 206924/306113 [00:39<00:21, 4592.71it/s]\u001b[A\n"," 68%|██████▊   | 207446/306113 [00:39<00:20, 4755.68it/s]\u001b[A\n"," 68%|██████▊   | 208000/306113 [00:39<00:20, 4836.58it/s]\u001b[A\n"," 68%|██████▊   | 208600/306113 [00:39<00:19, 4998.40it/s]\u001b[A\n"," 68%|██████▊   | 209200/306113 [00:40<00:18, 5152.27it/s]\u001b[A\n"," 69%|██████▊   | 209800/306113 [00:40<00:18, 5179.68it/s]\u001b[A\n"," 69%|██████▊   | 210400/306113 [00:40<00:18, 5195.68it/s]\u001b[A\n"," 69%|██████▉   | 211000/306113 [00:40<00:18, 5252.97it/s]\u001b[A\n"," 69%|██████▉   | 211600/306113 [00:40<00:17, 5321.21it/s]\u001b[A\n"," 69%|██████▉   | 212200/306113 [00:40<00:17, 5368.13it/s]\u001b[A\n"," 70%|██████▉   | 212800/306113 [00:40<00:17, 5274.27it/s]\u001b[A\n"," 70%|██████▉   | 213400/306113 [00:40<00:17, 5269.24it/s]\u001b[A\n"," 70%|██████▉   | 213928/306113 [00:40<00:17, 5242.94it/s]\u001b[A\n"," 70%|███████   | 214500/306113 [00:41<00:17, 5236.45it/s]\u001b[A\n"," 70%|███████   | 215100/306113 [00:41<00:17, 5187.58it/s]\u001b[A\n"," 70%|███████   | 215700/306113 [00:41<00:17, 5172.56it/s]\u001b[A\n"," 71%|███████   | 216300/306113 [00:41<00:17, 5224.14it/s]\u001b[A\n"," 71%|███████   | 216900/306113 [00:41<00:17, 5200.41it/s]\u001b[A\n"," 71%|███████   | 217421/306113 [00:41<00:18, 4846.03it/s]\u001b[A\n"," 71%|███████   | 218000/306113 [00:41<00:17, 4915.20it/s]\u001b[A\n"," 71%|███████▏  | 218500/306113 [00:41<00:17, 4937.02it/s]\u001b[A\n"," 72%|███████▏  | 219000/306113 [00:41<00:17, 4949.49it/s]\u001b[A\n"," 72%|███████▏  | 219600/306113 [00:42<00:17, 4984.69it/s]\u001b[A\n"," 72%|███████▏  | 220200/306113 [00:42<00:17, 5001.20it/s]\u001b[A\n"," 72%|███████▏  | 220701/306113 [00:42<00:17, 4892.99it/s]\u001b[A\n"," 72%|███████▏  | 221200/306113 [00:42<00:17, 4787.61it/s]\u001b[A\n"," 72%|███████▏  | 221800/306113 [00:42<00:17, 4922.92it/s]\u001b[A\n"," 73%|███████▎  | 222300/306113 [00:42<00:16, 4932.81it/s]\u001b[A\n"," 73%|███████▎  | 222900/306113 [00:42<00:16, 5122.46it/s]\u001b[A\n"," 73%|███████▎  | 223500/306113 [00:42<00:15, 5172.17it/s]\u001b[A\n"," 73%|███████▎  | 224018/306113 [00:42<00:15, 5159.90it/s]\u001b[A\n"," 73%|███████▎  | 224600/306113 [00:43<00:15, 5228.28it/s]\u001b[A\n"," 74%|███████▎  | 225200/306113 [00:43<00:15, 5231.23it/s]\u001b[A\n"," 74%|███████▍  | 225800/306113 [00:43<00:15, 5236.96it/s]\u001b[A\n"," 74%|███████▍  | 226400/306113 [00:43<00:14, 5317.23it/s]\u001b[A\n"," 74%|███████▍  | 227000/306113 [00:43<00:14, 5291.37it/s]\u001b[A\n"," 74%|███████▍  | 227600/306113 [00:43<00:14, 5261.49it/s]\u001b[A\n"," 75%|███████▍  | 228200/306113 [00:43<00:15, 5193.54it/s]\u001b[A\n"," 75%|███████▍  | 228720/306113 [00:43<00:14, 5194.65it/s]\u001b[A\n"," 75%|███████▍  | 229240/306113 [00:43<00:14, 5181.80it/s]\u001b[A\n"," 75%|███████▌  | 229800/306113 [00:44<00:14, 5133.23it/s]\u001b[A\n"," 75%|███████▌  | 230400/306113 [00:44<00:14, 5212.06it/s]\u001b[A\n"," 75%|███████▌  | 230922/306113 [00:44<00:14, 5196.39it/s]\u001b[A\n"," 76%|███████▌  | 231442/306113 [00:44<00:14, 5166.51it/s]\u001b[A\n"," 76%|███████▌  | 232000/306113 [00:44<00:14, 5082.80it/s]\u001b[A\n"," 76%|███████▌  | 232509/306113 [00:44<00:14, 4999.63it/s]\u001b[A\n"," 76%|███████▌  | 233100/306113 [00:44<00:14, 5148.10it/s]\u001b[A\n"," 76%|███████▋  | 233700/306113 [00:44<00:13, 5230.45it/s]\u001b[A\n"," 77%|███████▋  | 234300/306113 [00:44<00:13, 5325.04it/s]\u001b[A\n"," 77%|███████▋  | 234833/306113 [00:45<00:13, 5293.04it/s]\u001b[A\n"," 77%|███████▋  | 235400/306113 [00:45<00:13, 5175.61it/s]\u001b[A\n"," 77%|███████▋  | 236000/306113 [00:45<00:13, 5259.39it/s]\u001b[A\n"," 77%|███████▋  | 236600/306113 [00:45<00:13, 5308.83it/s]\u001b[A\n"," 77%|███████▋  | 237200/306113 [00:45<00:12, 5357.43it/s]\u001b[A\n"," 78%|███████▊  | 237800/306113 [00:45<00:12, 5351.99it/s]\u001b[A\n"," 78%|███████▊  | 238400/306113 [00:45<00:12, 5342.04it/s]\u001b[A\n"," 78%|███████▊  | 239000/306113 [00:45<00:12, 5331.00it/s]\u001b[A\n"," 78%|███████▊  | 239600/306113 [00:45<00:12, 5363.85it/s]\u001b[A\n"," 78%|███████▊  | 240200/306113 [00:46<00:12, 5362.75it/s]\u001b[A\n"," 79%|███████▊  | 240800/306113 [00:46<00:12, 5373.92it/s]\u001b[A\n"," 79%|███████▉  | 241400/306113 [00:46<00:12, 5370.39it/s]\u001b[A\n"," 79%|███████▉  | 242000/306113 [00:46<00:11, 5477.46it/s]\u001b[A\n"," 79%|███████▉  | 242600/306113 [00:46<00:11, 5412.87it/s]\u001b[A\n"," 79%|███████▉  | 243200/306113 [00:46<00:11, 5416.10it/s]\u001b[A\n"," 80%|███████▉  | 243800/306113 [00:46<00:11, 5447.62it/s]\u001b[A\n"," 80%|███████▉  | 244400/306113 [00:46<00:11, 5373.00it/s]\u001b[A\n"," 80%|████████  | 245000/306113 [00:46<00:11, 5519.37it/s]\u001b[A\n"," 80%|████████  | 245600/306113 [00:47<00:11, 5398.65it/s]\u001b[A\n"," 80%|████████  | 246142/306113 [00:47<00:11, 5359.70it/s]\u001b[A\n"," 81%|████████  | 246700/306113 [00:47<00:11, 5193.00it/s]\u001b[A\n"," 81%|████████  | 247221/306113 [00:47<00:11, 5035.40it/s]\u001b[A\n"," 81%|████████  | 247726/306113 [00:47<00:12, 4504.98it/s]\u001b[A\n"," 81%|████████  | 248300/306113 [00:47<00:12, 4664.21it/s]\u001b[A\n"," 81%|████████▏ | 248900/306113 [00:47<00:11, 4874.45it/s]\u001b[A\n"," 82%|████████▏ | 249500/306113 [00:47<00:11, 5085.48it/s]\u001b[A\n"," 82%|████████▏ | 250100/306113 [00:47<00:10, 5287.28it/s]\u001b[A\n"," 82%|████████▏ | 250700/306113 [00:48<00:10, 5276.20it/s]\u001b[A\n"," 82%|████████▏ | 251232/306113 [00:48<00:10, 5278.06it/s]\u001b[A\n"," 82%|████████▏ | 251800/306113 [00:48<00:10, 5157.32it/s]\u001b[A\n"," 82%|████████▏ | 252400/306113 [00:48<00:10, 5249.51it/s]\u001b[A\n"," 83%|████████▎ | 253000/306113 [00:48<00:10, 5206.76it/s]\u001b[A\n"," 83%|████████▎ | 253600/306113 [00:48<00:10, 5242.11it/s]\u001b[A\n"," 83%|████████▎ | 254200/306113 [00:48<00:09, 5215.07it/s]\u001b[A\n"," 83%|████████▎ | 254800/306113 [00:48<00:09, 5227.93it/s]\u001b[A\n"," 83%|████████▎ | 255400/306113 [00:48<00:09, 5235.60it/s]\u001b[A\n"," 84%|████████▎ | 256000/306113 [00:49<00:09, 5230.61it/s]\u001b[A\n"," 84%|████████▍ | 256600/306113 [00:49<00:09, 5264.17it/s]\u001b[A\n"," 84%|████████▍ | 257200/306113 [00:49<00:09, 5310.04it/s]\u001b[A\n"," 84%|████████▍ | 257800/306113 [00:49<00:09, 5300.36it/s]\u001b[A\n"," 84%|████████▍ | 258400/306113 [00:49<00:09, 5253.26it/s]\u001b[A\n"," 85%|████████▍ | 259000/306113 [00:49<00:08, 5234.94it/s]\u001b[A\n"," 85%|████████▍ | 259600/306113 [00:49<00:08, 5284.60it/s]\u001b[A\n"," 85%|████████▌ | 260200/306113 [00:49<00:08, 5389.87it/s]\u001b[A\n"," 85%|████████▌ | 260800/306113 [00:50<00:08, 5301.61it/s]\u001b[A\n"," 85%|████████▌ | 261331/306113 [00:50<00:08, 5278.11it/s]\u001b[A\n"," 86%|████████▌ | 261900/306113 [00:50<00:09, 4743.02it/s]\u001b[A\n"," 86%|████████▌ | 262500/306113 [00:50<00:08, 4891.40it/s]\u001b[A\n"," 86%|████████▌ | 263100/306113 [00:50<00:08, 4944.26it/s]\u001b[A\n"," 86%|████████▌ | 263700/306113 [00:50<00:08, 5006.85it/s]\u001b[A\n"," 86%|████████▋ | 264300/306113 [00:50<00:08, 5074.02it/s]\u001b[A\n"," 87%|████████▋ | 264900/306113 [00:50<00:08, 5073.53it/s]\u001b[A\n"," 87%|████████▋ | 265500/306113 [00:50<00:07, 5209.43it/s]\u001b[A\n"," 87%|████████▋ | 266024/306113 [00:51<00:07, 5152.22it/s]\u001b[A\n"," 87%|████████▋ | 266600/306113 [00:51<00:07, 5190.35it/s]\u001b[A\n"," 87%|████████▋ | 267200/306113 [00:51<00:07, 5244.75it/s]\u001b[A\n"," 87%|████████▋ | 267726/306113 [00:51<00:07, 5173.88it/s]\u001b[A\n"," 88%|████████▊ | 268300/306113 [00:51<00:07, 5131.77it/s]\u001b[A\n"," 88%|████████▊ | 268900/306113 [00:51<00:07, 5193.72it/s]\u001b[A\n"," 88%|████████▊ | 269500/306113 [00:51<00:07, 5175.85it/s]\u001b[A\n"," 88%|████████▊ | 270100/306113 [00:51<00:06, 5278.57it/s]\u001b[A\n"," 88%|████████▊ | 270700/306113 [00:51<00:06, 5315.63it/s]\u001b[A\n"," 89%|████████▊ | 271232/306113 [00:52<00:06, 5305.09it/s]\u001b[A\n"," 89%|████████▉ | 271800/306113 [00:52<00:06, 5274.05it/s]\u001b[A\n"," 89%|████████▉ | 272328/306113 [00:52<00:07, 4640.56it/s]\u001b[A\n"," 89%|████████▉ | 272900/306113 [00:52<00:06, 4752.85it/s]\u001b[A\n"," 89%|████████▉ | 273500/306113 [00:52<00:06, 4880.85it/s]\u001b[A\n"," 90%|████████▉ | 274100/306113 [00:52<00:06, 4921.75it/s]\u001b[A\n"," 90%|████████▉ | 274700/306113 [00:52<00:06, 5047.31it/s]\u001b[A\n"," 90%|████████▉ | 275209/306113 [00:52<00:06, 5054.13it/s]\u001b[A\n"," 90%|█████████ | 275744/306113 [00:52<00:05, 5136.16it/s]\u001b[A\n"," 90%|█████████ | 276261/306113 [00:53<00:05, 4989.10it/s]\u001b[A\n"," 90%|█████████ | 276800/306113 [00:53<00:05, 4997.46it/s]\u001b[A\n"," 91%|█████████ | 277400/306113 [00:53<00:05, 5058.76it/s]\u001b[A\n"," 91%|█████████ | 278000/306113 [00:53<00:05, 5154.05it/s]\u001b[A\n"," 91%|█████████ | 278600/306113 [00:53<00:05, 5192.96it/s]\u001b[A\n"," 91%|█████████ | 279120/306113 [00:53<00:05, 5190.14it/s]\u001b[A\n"," 91%|█████████▏| 279700/306113 [00:53<00:05, 5152.23it/s]\u001b[A\n"," 92%|█████████▏| 280300/306113 [00:53<00:05, 5136.72it/s]\u001b[A\n"," 92%|█████████▏| 280900/306113 [00:53<00:04, 5260.80it/s]\u001b[A\n"," 92%|█████████▏| 281500/306113 [00:54<00:04, 5374.87it/s]\u001b[A\n"," 92%|█████████▏| 282100/306113 [00:54<00:04, 5494.53it/s]\u001b[A\n"," 92%|█████████▏| 282700/306113 [00:54<00:04, 5363.71it/s]\u001b[A\n"," 93%|█████████▎| 283300/306113 [00:54<00:04, 5359.98it/s]\u001b[A\n"," 93%|█████████▎| 283900/306113 [00:54<00:04, 5391.32it/s]\u001b[A\n"," 93%|█████████▎| 284500/306113 [00:54<00:04, 5357.76it/s]\u001b[A\n"," 93%|█████████▎| 285100/306113 [00:54<00:03, 5341.80it/s]\u001b[A\n"," 93%|█████████▎| 285635/306113 [00:54<00:03, 5331.18it/s]\u001b[A\n"," 93%|█████████▎| 286169/306113 [00:54<00:03, 5286.36it/s]\u001b[A\n"," 94%|█████████▎| 286698/306113 [00:55<00:03, 5243.94it/s]\u001b[A\n"," 94%|█████████▍| 287223/306113 [00:55<00:03, 5082.56it/s]\u001b[A\n"," 94%|█████████▍| 287800/306113 [00:55<00:03, 5149.08it/s]\u001b[A\n"," 94%|█████████▍| 288400/306113 [00:55<00:03, 5194.93it/s]\u001b[A\n"," 94%|█████████▍| 289000/306113 [00:55<00:03, 5212.74it/s]\u001b[A\n"," 95%|█████████▍| 289600/306113 [00:55<00:03, 5234.57it/s]\u001b[A\n"," 95%|█████████▍| 290124/306113 [00:55<00:03, 5201.07it/s]\u001b[A\n"," 95%|█████████▍| 290700/306113 [00:55<00:02, 5157.48it/s]\u001b[A\n"," 95%|█████████▌| 291300/306113 [00:55<00:02, 5230.18it/s]\u001b[A\n"," 95%|█████████▌| 291900/306113 [00:56<00:02, 5315.62it/s]\u001b[A\n"," 96%|█████████▌| 292500/306113 [00:56<00:02, 5344.05it/s]\u001b[A\n"," 96%|█████████▌| 293100/306113 [00:56<00:02, 5354.57it/s]\u001b[A\n"," 96%|█████████▌| 293636/306113 [00:56<00:02, 4771.70it/s]\u001b[A\n"," 96%|█████████▌| 294200/306113 [00:56<00:02, 4833.15it/s]\u001b[A\n"," 96%|█████████▋| 294800/306113 [00:56<00:02, 5054.52it/s]\u001b[A\n"," 97%|█████████▋| 295400/306113 [00:56<00:02, 5238.88it/s]\u001b[A\n"," 97%|█████████▋| 295930/306113 [00:56<00:01, 5195.15it/s]\u001b[A\n"," 97%|█████████▋| 296500/306113 [00:56<00:01, 5234.41it/s]\u001b[A\n"," 97%|█████████▋| 297100/306113 [00:57<00:01, 5289.94it/s]\u001b[A\n"," 97%|█████████▋| 297700/306113 [00:57<00:01, 5321.70it/s]\u001b[A\n"," 97%|█████████▋| 298300/306113 [00:57<00:01, 5366.39it/s]\u001b[A\n"," 98%|█████████▊| 298900/306113 [00:57<00:01, 5397.87it/s]\u001b[A\n"," 98%|█████████▊| 299500/306113 [00:57<00:01, 5441.41it/s]\u001b[A\n"," 98%|█████████▊| 300100/306113 [00:57<00:01, 5356.01it/s]\u001b[A\n"," 98%|█████████▊| 300637/306113 [00:57<00:01, 5249.48it/s]\u001b[A\n"," 98%|█████████▊| 301163/306113 [00:57<00:00, 5228.04it/s]\u001b[A\n"," 99%|█████████▊| 301700/306113 [00:57<00:00, 5062.42it/s]\u001b[A\n"," 99%|█████████▉| 302300/306113 [00:58<00:00, 5164.43it/s]\u001b[A\n"," 99%|█████████▉| 302817/306113 [00:58<00:00, 5163.55it/s]\u001b[A\n"," 99%|█████████▉| 303400/306113 [00:58<00:00, 5155.10it/s]\u001b[A\n"," 99%|█████████▉| 304000/306113 [00:58<00:00, 5247.54it/s]\u001b[A\n","100%|█████████▉| 304600/306113 [00:58<00:00, 5285.12it/s]\u001b[A\n","100%|█████████▉| 305200/306113 [00:58<00:00, 5244.72it/s]\u001b[A\n","100%|██████████| 306113/306113 [00:58<00:00, 5207.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch [1/20], Loss: 1.5645\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 306113/306113 [00:57<00:00, 5326.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch [2/20], Loss: 0.9994\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 306113/306113 [00:57<00:00, 5330.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch [3/20], Loss: 0.9185\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 306113/306113 [00:58<00:00, 5267.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch [4/20], Loss: 0.8833\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 306113/306113 [00:57<00:00, 5339.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch [5/20], Loss: 0.8554\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 306113/306113 [00:57<00:00, 5321.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch [6/20], Loss: 0.8363\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 306113/306113 [00:57<00:00, 5354.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch [7/20], Loss: 0.8237\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 306113/306113 [00:56<00:00, 5435.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch [8/20], Loss: 0.8118\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 306113/306113 [00:56<00:00, 5426.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch [9/20], Loss: 0.8016\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 306113/306113 [00:56<00:00, 5373.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch [10/20], Loss: 0.7933\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 306113/306113 [00:57<00:00, 5331.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch [11/20], Loss: 0.7846\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 306113/306113 [00:56<00:00, 5433.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch [12/20], Loss: 0.7770\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 306113/306113 [00:56<00:00, 5440.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch [13/20], Loss: 0.7716\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 306113/306113 [00:56<00:00, 5422.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch [14/20], Loss: 0.7644\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 306113/306113 [00:56<00:00, 5423.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch [15/20], Loss: 0.7562\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 306113/306113 [00:56<00:00, 5433.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch [16/20], Loss: 0.7521\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 306113/306113 [00:56<00:00, 5407.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch [17/20], Loss: 0.7441\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 306113/306113 [00:56<00:00, 5403.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch [18/20], Loss: 0.7371\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 306113/306113 [00:56<00:00, 5417.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["epoch [19/20], Loss: 0.7294\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 306113/306113 [00:56<00:00, 5443.36it/s]"]},{"output_type":"stream","name":"stdout","text":["epoch [20/20], Loss: 0.7230\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["import os\n","import shutil\n","import pickle as pk\n","from torch.utils.tensorboard import SummaryWriter\n","# 记录日志\n","shutil.rmtree('textrcnn') if os.path.exists('textrcnn') else 1\n","writer = SummaryWriter('./textrcnn', comment='textrcnn')\n","\n","# 构建模型\n","model = TextRCNN(parameter).to(parameter['cuda'])\n","\n","# 确定训练模式\n","model.train()\n","\n","# 确定优化器和损失\n","optimizer = torch.optim.SGD(model.parameters(),lr=0.001, momentum=0.95, nesterov=True)\n","# optimizer = torch.optim.Adam(model.parameters(),lr = parameter['lr'], \\\n","#                              weight_decay = 0.01)\n","criterion = nn.CrossEntropyLoss()\n","\n","# # 保存图\n","# train_yield = batch_yield(train_chars,train_labels,parameter)\n","# seqs,label,_,keys,epoch = next(train_yield)\n","# writer.add_graph(model, (seqs,))\n","\n","# 准备迭代器\n","train_yield = batch_yield(train_chars,train_labels,parameter)\n","\n","# 开始训练\n","loss_cal = []\n","min_loss = float('inf')\n","if os.path.exists('model-rcnn.h5'):\n","  print('model-rcnn.h5 exist!')\n","else:\n","  print('model not exist!')\n","  with writer:\n","      while 1:\n","          seqs,label,_,keys,epoch = next(train_yield)\n","          if not keys:\n","              break\n","          out = model(seqs)\n","          loss = criterion(out, label)\n","          optimizer.zero_grad()\n","          loss.backward()\n","          optimizer.step()\n","          loss_cal.append(loss.item())\n","          if epoch is not None:\n","              if (epoch+1)%1 == 0:\n","                  loss_cal = sum(loss_cal)/len(loss_cal)\n","                  if loss_cal < min_loss:\n","                      min_loss = loss_cal\n","                      torch.save(model.state_dict(), 'model-rcnn.h5')\n","                  print('epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, \\\n","                                                        parameter['epoch'],loss_cal))\n","              writer.add_scalar('loss',loss_cal,global_step=epoch+1)\n","              loss_cal = [loss.item()]\n","      writer.flush()\n","      writer.close()\n","      \n","  # torch.save(model.state_dict(), 'model-rcnn.h5')"]},{"cell_type":"markdown","metadata":{"id":"_PnOTuIJ2jDS"},"source":["# textRNN+Attention（HAN）"]},{"cell_type":"markdown","metadata":{"id":"JMAE9_Lw2jDS"},"source":["## textRNN+Attention模型实现"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jUCGjCIY2jDS"},"outputs":[],"source":["import torch.nn.functional as F # pytorch 激活函数的类\n","from torch import nn,optim # 构建模型和优化器\n","\n","# 构建分类模型\n","class TextRNN_Attention(nn.Module):\n","    def __init__(self, parameter):\n","        super(TextRNN_Attention, self).__init__()\n","        embedding_dim = parameter['embedding_dim']\n","        hidden_size = parameter['hidden_size']\n","        output_size = parameter['output_size']\n","        num_layers = parameter['num_layers']\n","        dropout = parameter['dropout']\n","        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, bidirectional=True, batch_first=True, dropout=dropout)\n","        self.fc_attention = nn.Linear(hidden_size*2, hidden_size*2)\n","        self.fc = nn.Linear(hidden_size*2, output_size)\n","\n","        \n","        # attention\n","        self.w = nn.Parameter(torch.zeros(hidden_size * 2))\n","        \n","    def forward(self, x):\n","        out,(h, c)= self.lstm(x)\n","        alpha = F.softmax(torch.matmul(F.tanh(self.fc_attention(out)),self.w),dim = 1).unsqueeze(-1)\n","        print(alpha.shape)\n","#         alpha = F.softmax(torch.matmul(F.tanh(out),self.w),dim = 1).unsqueeze(-1)\n","#         print(out.shape,alpha.shape)\n","        out = F.relu(torch.sum(out * alpha,1))\n","#         print(out.shape)\n","        out = self.fc(out)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jrf5uO3_2jDT","outputId":"0c96aa8b-d64c-4ff7-f975-4e9c3ed54965","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641214621117,"user_tz":-480,"elapsed":15,"user":{"displayName":"aiden zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00038965460335847869"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([100, 32, 1])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"]},{"output_type":"execute_result","data":{"text/plain":["torch.Size([100, 15])"]},"metadata":{},"execution_count":18}],"source":["rnn_attention = TextRNN_Attention(parameter)\n","rnn_attention(torch.rand(100,32,300)).shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GOq_cHEj2jDT","outputId":"e9bb133f-2441-4674-c429-1a6a52827162","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641214621676,"user_tz":-480,"elapsed":567,"user":{"displayName":"aiden zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00038965460335847869"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n"]},{"output_type":"stream","name":"stdout","text":["torch.Size([100, 32, 1])\n","torch.Size([100, 32, 1])\n","torch.Size([100, 32, 1])\n"]}],"source":["from torch.utils.tensorboard import SummaryWriter\n","x = torch.rand(100,32,300)\n","model = TextRNN_Attention(parameter)\n"," \n","with SummaryWriter(comment='textrnn_attention') as w:\n","    w.add_graph(model, x)  "]},{"cell_type":"markdown","metadata":{"id":"bS006pWS2jDT"},"source":["## textRNN+Attention模型训练"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2buM8adq2jDU"},"outputs":[],"source":["import os\n","import shutil\n","import pickle as pk\n","from torch.utils.tensorboard import SummaryWriter\n","\n","# 记录日志\n","shutil.rmtree('textrnn+Attention') if os.path.exists('textrnn+Attention') else 1\n","writer = SummaryWriter('./textrnn+Attention', comment='textrnn+Attention')\n","\n","# 构建模型\n","model = TextRNN_Attention(parameter).to(parameter['cuda'])\n","\n","# 确定训练模式\n","model.train()\n","\n","# 确定优化器和损失\n","optimizer = torch.optim.SGD(model.parameters(),lr=0.01, momentum=0.95, nesterov=True)\n","# optimizer = torch.optim.Adam(model.parameters(),lr = parameter['lr'], \\\n","#                              weight_decay = 0.01)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.1)\n","criterion = nn.CrossEntropyLoss()\n","\n","# 保存图\n","# train_yield = batch_yield(train_chars,train_labels,parameter)\n","# seqs,label,keys,epoch = next(train_yield)\n","# writer.add_graph(model, (seqs,))\n","\n","# 准备迭代器\n","train_yield = batch_yield(train_chars,train_labels,parameter)\n","\n","# 开始训练\n","loss_cal = []\n","min_loss = float('inf')\n","num = 0\n","if os.path.exists('model-rnn+Attention.h5'):\n","  print('model-rnn+Attention.h5 exist!')\n","else:\n","  with writer:\n","      while 1:\n","          num += 1\n","          seqs,label,_,keys,epoch = next(train_yield)\n","          if not keys:\n","              break\n","          out = model(seqs)\n","          loss = criterion(out, label)\n","          optimizer.zero_grad()\n","          loss.backward()\n","          optimizer.step()\n","          loss_cal.append(loss.item())\n","          if num % 100 == 0:\n","              print(loss.item())\n","          if epoch is not None:\n","              if (epoch+1)%1 == 0:\n","                  loss_cal = sum(loss_cal)/len(loss_cal)\n","                  if loss_cal < min_loss:\n","                      min_loss = loss_cal\n","                      torch.save(model.state_dict(), 'model-rnn+Attention.h5')\n","                  for param_group in optimizer.param_groups:\n","                      now_lr = param_group['lr']\n","                  print('epoch [{}/{}], Loss: {:.4f}, lr:{}'.format(epoch+1, \\\n","                                                        parameter['epoch'],loss_cal,str(now_lr)))\n","                  scheduler.step()\n","              writer.add_scalar('loss',loss_cal,global_step=epoch+1)\n","              loss_cal = [loss.item()]\n","  #     writer.flush()\n","      writer.close()\n","      \n","  # torch.save(model.state_dict(), 'model-rnn.h5')"]},{"cell_type":"markdown","metadata":{"id":"LKr17Dud2jDU"},"source":["# transformerEncoder"]},{"cell_type":"markdown","metadata":{"id":"fmYNFJJx2jDU"},"source":["## transformerEncoder模型实现"]},{"cell_type":"markdown","metadata":{"id":"AvV4sxvk2jDU"},"source":["### 位置层"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"x1BLWOaq2jDV","executionInfo":{"status":"ok","timestamp":1641220421569,"user_tz":-480,"elapsed":464,"user":{"displayName":"aiden zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00038965460335847869"}}},"outputs":[],"source":["import torch.nn.functional as F # pytorch 激活函数的类\n","from torch import nn,optim # 构建模型和优化器\n","\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, parameter):#d_model, dropout=0.1, max_len=200):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=parameter['dropout'])\n","        d_model = parameter['embedding_dim']\n","        max_len = parameter['max_len']\n","\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer('pe', pe)\n","        print(pe,pe.shape)\n","\n","    def forward(self, x):\n","        '''\n","        x: [seq_len, batch_size, d_model]\n","        '''\n","        x = x + self.pe[:x.size(0), :]\n","        return self.dropout(x)\n","    \n","def get_attn_pad_mask(q_len_list, k_len_list):\n","    global device\n","    len_q = max(q_len_list)\n","    len_k = max(k_len_list)\n","    batch_size = len(q_len_list)\n","    pad_attn_mask =  torch.from_numpy(np.array([[False]*i+[True]*(len_k-i) for i in k_len_list])).unsqueeze(1)\n","    return pad_attn_mask.expand(batch_size, len_q, len_k).byte().to(device)  # [batch_size, len_q, len_k]\n","    "]},{"cell_type":"markdown","metadata":{"id":"lh7EdaRm2jDV"},"source":["- Question：\n","    1. 位置层的作用？\n","        - 位置编码是Transformer框架中特有的组成部分，补充了Attention机制本身不能捕捉位置信息的缺陷\n","        \n","    2. 为什么用正余弦函数来处理位置层？\n","        - $论文中使用的Positional Encoding(PE)是正余弦函数，位置(pos)越小，波长越长，每一个位置对应的PE都是唯一的。同时作者也提到，之所以选用正余弦函数作为PE，是因为这可以使得模型学习到token之间的相对位置关系。因为对于任意一个偏移量K，PE_(pos+k)可以由PE_(pos)线性表示，差了几个\\pi /2$\n","    \n","    3. 位置层如何使用？\n","        - $Positional Embedding的成分直接叠加于Embedding之上，使得每个token的位置信息和它的语义信息(embedding)充分融合，并被传递到后续所有经过复杂变换的序列表达中去。$"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":377,"status":"ok","timestamp":1641220426307,"user":{"displayName":"aiden zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00038965460335847869"},"user_tz":-480},"id":"YtEjDPO92jDV","outputId":"193c1897-5ba8-4fc7-eadd-3353a17116db"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n","           0.0000e+00,  1.0000e+00]],\n","\n","        [[ 8.4147e-01,  5.4030e-01,  8.0782e-01,  ...,  1.0000e+00,\n","           1.0633e-04,  1.0000e+00]],\n","\n","        [[ 9.0930e-01, -4.1615e-01,  9.5231e-01,  ...,  1.0000e+00,\n","           2.1267e-04,  1.0000e+00]],\n","\n","        ...,\n","\n","        [[-8.9797e-01, -4.4006e-01,  9.8994e-01,  ...,  9.9365e-01,\n","           1.0582e-01,  9.9439e-01]],\n","\n","        [[-8.5547e-01,  5.1785e-01,  6.9774e-01,  ...,  9.9364e-01,\n","           1.0592e-01,  9.9437e-01]],\n","\n","        [[-2.6461e-02,  9.9965e-01, -1.6740e-01,  ...,  9.9363e-01,\n","           1.0603e-01,  9.9436e-01]]]) torch.Size([1000, 1, 300])\n"]},{"output_type":"execute_result","data":{"text/plain":["(torch.Size([100, 40, 300]),\n"," torch.Size([100, 40, 300]),\n"," torch.Size([100, 40, 40]),\n"," 1000,\n"," 300)"]},"metadata":{},"execution_count":6}],"source":["# have a test\n","test = PositionalEncoding(parameter).to(device)\n","mask = get_attn_pad_mask(x_len,x_len)\n","seqs.shape,test(seqs).shape,mask.shape,parameter['max_len'],parameter['embedding_dim']"]},{"cell_type":"markdown","metadata":{"id":"k9vYWppn2jDV"},"source":["### block（multi-head self attention + Add & Normalize + Feed Forward Network）"]},{"cell_type":"markdown","metadata":{"id":"PCragtTq2jDW"},"source":["*multi-head self attention + ADD & Normalize"]},{"cell_type":"markdown","metadata":{"id":"V7cjuOct2jDW"},"source":["$Attention通常可以进行如下描述，表示为将query(Q)和key-value pairs映射到输出上，其中query、每个key、每个value都是向量，输出是V中所有values的加权，其中权重是由Query和每个key计算出来的，计算方法分为三步：$\n","\n","- $1.计算比较Q和K的相似度，用f来表示：$\n","\n","$$f(Q,K_{i})_{i = 1,2,3}$$\n","- $2.将得到的相似度进行softmax归一化：$\n","\n","$$\\alpha_{i} = \\frac{e^{f(Q,K_{i})}}{\\sum_{j = 1}^{m}e^{f(Q,K_{i})}}_{j = 1,2,3}$$\n","- $3.针对计算出来的权重，对所有的values进行加权求和，得到Attention向量：$\n","\n","$$\\sum_{i=1}^{m}\\alpha_{i}V_{i}$$\n","-  $ex1.相似度的计算有以下4种：$\n","    \n","$$点乘 dot product： f(Q,K_{i}) = Q^TK_{i}$$\n","$$权重 General： f(Q,K_{i}) = Q^TWK_{i}$$\n","$$拼接权重 Concat： f(Q,K_{i}) = W[Q^T;K_{i}]$$\n","$$感知器 Perceptron： f(Q,K_{i}) = V^Ttanh(WQ+UK_{i})$$\n","\n","- $ex2.Q、K、V意义：$\n","\n","$$其中Q、K、V是输入通过一层全连接得到，相当于W_{Q}^TX、W_{K}^TX、W_{V}^TX$$\n","\n","- $整个过程相当于：$\n","\n","$输入（768维的词向量序列）通过全连接，分别映射至Q、K、V（64*nheads维度上），通过Q^TK点乘得到Q和K之间的相似度，然后通过softmax得到Q在K上各个得分，Softmax(Q^TK)，这个softmax的分数决定了当前单词在每个句子中每个单词位置的表示程度；然后V^T(Q^TK)，这里实际上的意义在于保存对当前词的关注度不变的情况下，降低对不相关词的关注。$"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"yO2h3XFF2jDW","executionInfo":{"status":"ok","timestamp":1641220430192,"user_tz":-480,"elapsed":358,"user":{"displayName":"aiden zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00038965460335847869"}}},"outputs":[],"source":["class ScaledDotProductAttention(nn.Module):\n","    def __init__(self,parameter):\n","        super(ScaledDotProductAttention, self).__init__()\n","        self.d_k = parameter['d_k']\n","\n","    def forward(self, Q, K, V, attn_mask):\n","        '''\n","        Q: [batch_size, n_heads, len_q, d_k]\n","        K: [batch_size, n_heads, len_k, d_k]\n","        V: [batch_size, n_heads, len_v(=len_k), d_v]\n","        attn_mask: [batch_size, n_heads, seq_len, seq_len]\n","        '''\n","        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(self.d_k) # scores : [batch_size, n_heads, len_q, len_k]\n","        scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is True.\n","#         print(scores)\n","#         print('scores:',scores.shape)\n","        attn = nn.Softmax(dim=-1)(scores)\n","#         print(attn)\n","#         print('attn:',attn.shape)\n","        context = torch.matmul(attn, V) # [batch_size, n_heads, len_q, d_v]\n","#         print('context:',context.shape)\n","        return context, attn\n","    \n","class MultiHeadAttention(nn.Module):\n","    def __init__(self,parameter):\n","        super(MultiHeadAttention, self).__init__()\n","        device = parameter['cuda']\n","        self.d_q,self.d_k,self.d_v,self.d_model,self.n_heads = parameter['d_q'],parameter['d_k'], \\\n","        parameter['d_v'],parameter['embedding_dim'],parameter['n_heads']\n","        self.W_Q = nn.Linear(self.d_model, self.d_q * self.n_heads, bias=False)\n","        self.W_K = nn.Linear(self.d_model, self.d_k * self.n_heads, bias=False)\n","        self.W_V = nn.Linear(self.d_model, self.d_v * self.n_heads, bias=False)\n","        self.fc = nn.Linear(self.n_heads * self.d_v, self.d_model, bias=False)\n","        self.sdp = ScaledDotProductAttention(parameter).to(device)\n","        self.add_norm = nn.LayerNorm(self.d_model)\n","        \n","    def forward(self, input_Q, input_K, input_V, attn_mask):\n","        '''\n","        input_Q: [batch_size, len_q, d_model]\n","        input_K: [batch_size, len_k, d_model]\n","        input_V: [batch_size, len_v(=len_k), d_model]\n","        attn_mask: [batch_size, seq_len, seq_len]\n","        '''\n","#         print('input-shape',input_Q.shape)\n","        residual, batch_size = input_Q, input_Q.size(0)\n","        # (B, S, D) -proj-> (B, S, D_new) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n","        Q = self.W_Q(input_Q).view(batch_size, -1, self.n_heads, self.d_q).transpose(1,2)  # Q: [batch_size, n_heads, len_q, d_q]\n","        K = self.W_K(input_K).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)  # K: [batch_size, n_heads, len_k, d_k]\n","        V = self.W_V(input_V).view(batch_size, -1, self.n_heads, self.d_v).transpose(1,2)  # V: [batch_size, n_heads, len_v(=len_k), d_v]\n","#         print('QKV-shape',Q.shape,K.shape,V.shape)\n","#         print('test:',K.transpose(-1,-2).shape)\n","#         print('attn-shape0:',attn_mask.shape)\n","#         print(attn_mask.shape)\n","        attn_mask_new = attn_mask.unsqueeze(1).repeat(1, self.n_heads, 1, 1) # attn_mask : [batch_size, n_heads, seq_len, seq_len]\n","#         print('attn-shape1:',attn_mask.shape)\n","#         print(attn_mask.shape)\n","        context, attn = self.sdp(Q, K, V, attn_mask_new)\n","        context = context.transpose(1, 2).reshape(batch_size, -1, self.n_heads * self.d_v) # context: [batch_size, len_q, n_heads * d_v]\n","        output = self.fc(context) # [batch_size, len_q, d_model]\n","        output = self.add_norm(output + residual)\n","        return output, attn"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":368,"status":"ok","timestamp":1641220432697,"user":{"displayName":"aiden zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00038965460335847869"},"user_tz":-480},"id":"wBu-5zCMmYwQ","outputId":"cde88384-bd35-40f3-b165-6ee0ddad8bb8"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/cuda/Indexing.cu:963.)\n","  \n"]}],"source":["mha = MultiHeadAttention(parameter).cuda()\n","mask = get_attn_pad_mask(x_len,x_len)\n","out = mha(seqs,seqs,seqs,mask)"]},{"cell_type":"markdown","metadata":{"id":"uVfyq3132jDX"},"source":["- Question：\n","    1. Multi-Head Attention的作用？\n","        - 将模型分为多个头，期望其形成多个相互独立子空间，可以让模型去关注不同方面的信息。但是也有很多论文不这么认为。也有人认为是计算复杂度的取舍。同时multi-head相对来说也比较冗余，mask掉一定比例的head对结果影响不大\n","        \n","    2. LN、BN、GN作用和区别？\n","        - Layer Normalization是一个通用的技术，其本质是规范优化空间，加速收敛。\n","        - 。。。课后自己补充下哈"]},{"cell_type":"markdown","metadata":{"id":"ED26DMEA2jDX"},"source":["### Feed Forward Network"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"4k8N3kCr2jDX","executionInfo":{"status":"ok","timestamp":1641220437172,"user_tz":-480,"elapsed":373,"user":{"displayName":"aiden zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00038965460335847869"}}},"outputs":[],"source":["class PoswiseFeedForwardNet(nn.Module):\n","    def __init__(self,parameter):\n","        self.d_ff,self.d_model = parameter['d_ff'],parameter['embedding_dim']\n","        super(PoswiseFeedForwardNet, self).__init__()\n","        self.fc = nn.Sequential(\n","            nn.Linear(self.d_model, self.d_ff, bias=False),\n","            nn.ReLU(),\n","            nn.Linear(self.d_ff, self.d_model, bias=False)\n","        )\n","        self.add_norm = nn.LayerNorm(self.d_model)\n","    def forward(self, inputs):\n","        '''\n","        inputs: [batch_size, seq_len, d_model]\n","        '''\n","        residual = inputs\n","        output = self.fc(inputs)\n","        return self.add_norm(output + residual) # [batch_size, seq_len, d_model]"]},{"cell_type":"markdown","metadata":{"id":"u_qZfKSQ2jDX"},"source":["- Question：\n","    1. Feed Forward Network的作用？\n","        - 其实，FFN的加入引入了非线性(ReLu激活函数)，变换了attention output的空间, 从而增加了模型的表现能力。把FFN去掉模型也是可以用的，但是效果差了很多。"]},{"cell_type":"markdown","metadata":{"id":"3kgG3cpg2jDX"},"source":["### Encoder实现\n","\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"lejizcq92jDY","executionInfo":{"status":"ok","timestamp":1641220440005,"user_tz":-480,"elapsed":4,"user":{"displayName":"aiden zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00038965460335847869"}}},"outputs":[],"source":["class EncoderLayer(nn.Module):\n","    def __init__(self,parameter):\n","        super(EncoderLayer, self).__init__()\n","        device = parameter['cuda']\n","        self.enc_self_attn = MultiHeadAttention(parameter).to(device)\n","        self.pos_ffn = PoswiseFeedForwardNet(parameter).to(device)\n","\n","    def forward(self, enc_inputs, enc_self_attn_mask):\n","        '''\n","        enc_inputs: [batch_size, src_len, d_model]\n","        enc_self_attn_mask: [batch_size, src_len, src_len]\n","        '''\n","        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) # enc_inputs to same Q,K,V\n","        enc_outputs = self.pos_ffn(enc_outputs) # enc_outputs: [batch_size, src_len, d_model]\n","        return enc_outputs, attn"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":587,"status":"ok","timestamp":1641220444567,"user":{"displayName":"aiden zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00038965460335847869"},"user_tz":-480},"id":"lSw5Y3XR2jDY","outputId":"3d993d97-8b8d-4601-9f0d-0acfcb5cabc3"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/cuda/Indexing.cu:963.)\n","  \n"]},{"output_type":"execute_result","data":{"text/plain":["torch.Size([100, 40, 300])"]},"metadata":{},"execution_count":11}],"source":["# have a test\n","test = EncoderLayer(parameter).to(device)\n","mask = get_attn_pad_mask(x_len,x_len)\n","context,attn = test(seqs,mask)\n","# attn\n","context.shape"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"U6MbT19p2jDY","executionInfo":{"status":"ok","timestamp":1641220446499,"user_tz":-480,"elapsed":2,"user":{"displayName":"aiden zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00038965460335847869"}}},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self,parameter):\n","        super(Encoder, self).__init__()\n","        n_layers = parameter['n_layers']\n","        self.pos_emb = PositionalEncoding(parameter)\n","        self.layers = nn.ModuleList([EncoderLayer(parameter) for _ in range(n_layers)])\n","\n","    def forward(self, enc_inputs,len_inputs):\n","        '''\n","        enc_inputs: [batch_size, src_len, d_model]\n","        '''\n","        enc_outputs = self.pos_emb(enc_inputs.transpose(0, 1)).transpose(0, 1) # [batch_size, src_len, d_model]\n","        enc_self_attn_mask = get_attn_pad_mask(len_inputs, len_inputs) # [batch_size, src_len, src_len]\n","        enc_self_attns = []\n","        for layer in self.layers:\n","            # enc_outputs: [batch_size, src_len, d_model], enc_self_attn: [batch_size, n_heads, src_len, src_len]\n","            enc_outputs, enc_self_attn = layer(enc_outputs, enc_self_attn_mask)\n","            enc_self_attns.append(enc_self_attn)\n","        return enc_outputs, enc_self_attns"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"suSA_s8u2jDY","executionInfo":{"status":"ok","timestamp":1641220449468,"user_tz":-480,"elapsed":367,"user":{"displayName":"aiden zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00038965460335847869"}}},"outputs":[],"source":["class transformerEncoder(nn.Module):\n","    def __init__(self,parameter):\n","        super(transformerEncoder, self).__init__()\n","        output_dim = parameter['output_size']\n","        d_model = parameter['embedding_dim']\n","        device = parameter['cuda']\n","        self.encoder = Encoder(parameter).to(device)\n","        self.fc = nn.Linear(d_model, output_dim)\n","        self.softmax = nn.Softmax(dim=-1)\n","        \n","    def forward(self,enc_inputs,len_inputs):\n","        enc_outputs, enc_self_attns = self.encoder(enc_inputs,len_inputs)\n","#         print(enc_outputs.shape)\n","#         enc_outputs = enc_outputs.permute(0, 2, 1)\n","        enc_outputs,_ = torch.max(enc_outputs, 1)\n","#         print(enc_outputs.shape)\n","        outputs = self.fc(enc_outputs)\n","        return outputs"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":399,"status":"ok","timestamp":1641220466898,"user":{"displayName":"aiden zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00038965460335847869"},"user_tz":-480},"id":"bawU6xvU2jDY","outputId":"f9e45d19-e4d6-43c9-cf0d-85eafa8b5313"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n","           0.0000e+00,  1.0000e+00]],\n","\n","        [[ 8.4147e-01,  5.4030e-01,  8.0782e-01,  ...,  1.0000e+00,\n","           1.0633e-04,  1.0000e+00]],\n","\n","        [[ 9.0930e-01, -4.1615e-01,  9.5231e-01,  ...,  1.0000e+00,\n","           2.1267e-04,  1.0000e+00]],\n","\n","        ...,\n","\n","        [[-8.9797e-01, -4.4006e-01,  9.8994e-01,  ...,  9.9365e-01,\n","           1.0582e-01,  9.9439e-01]],\n","\n","        [[-8.5547e-01,  5.1785e-01,  6.9774e-01,  ...,  9.9364e-01,\n","           1.0592e-01,  9.9437e-01]],\n","\n","        [[-2.6461e-02,  9.9965e-01, -1.6740e-01,  ...,  9.9363e-01,\n","           1.0603e-01,  9.9436e-01]]]) torch.Size([1000, 1, 300])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/cuda/Indexing.cu:963.)\n","  \n"]},{"output_type":"execute_result","data":{"text/plain":["torch.Size([100, 15])"]},"metadata":{},"execution_count":14}],"source":["test = transformerEncoder(parameter).to(device)\n","test(seqs,x_len).shape"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"JqE1VM5w2jDZ","outputId":"4baecaab-7b17-4112-87f3-906369d24d73","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641220470111,"user_tz":-480,"elapsed":5,"user":{"displayName":"aiden zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00038965460335847869"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([100, 40, 300]), 100)"]},"metadata":{},"execution_count":15}],"source":["seqs.shape,len(x_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZDD_aHq72jDZ"},"outputs":[],"source":["# from torch.utils.tensorboard import SummaryWriter\n","# x = torch.rand(100,32,300).to(device)\n","# x_len = torch.rand(100).to(device)\n","\n","# model = transformerEncoder(parameter)\n"," \n","# with SummaryWriter(comment='textrnn_attention') as w:\n","#     w.add_graph(model, (x,x_len))  "]},{"cell_type":"markdown","metadata":{"id":"z7xCk7F62jDZ"},"source":["## transformerEncoder模型训练"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1Fq4CU6PfK_l_7MAfsv2vjhaSdUbMm58D"},"id":"u2iRl60Q2jDZ","outputId":"9fa03687-5a65-45c5-fa9b-fd910838471a","executionInfo":{"status":"ok","timestamp":1641239676312,"user_tz":-480,"elapsed":19198928,"user":{"displayName":"aiden zhang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00038965460335847869"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import os\n","import shutil\n","import pickle as pk\n","from torch.utils.tensorboard import SummaryWriter\n","\n","# 记录日志\n","shutil.rmtree('transformerEncoder') if os.path.exists('transformerEncoder') else 1\n","writer = SummaryWriter('./transformerEncoder', comment='transformerEncoder')\n","\n","# 构建模型\n","model = transformerEncoder(parameter).to(parameter['cuda'])\n","\n","\n","# 确定训练模式\n","model.train()\n","\n","# 确定优化器和损失\n","optimizer = torch.optim.SGD(model.parameters(),lr=0.01, momentum=0.95, nesterov=True)\n","# optimizer = torch.optim.Adam(model.parameters(),lr=0.01)\n","# optimizer = torch.optim.Adam(model.parameters(),lr = parameter['lr'], \\\n","#                              weight_decay = 0.01)\n","criterion = nn.CrossEntropyLoss()\n","\n","# 保存图\n","# train_yield = batch_yield(train_chars,train_labels,parameter)\n","# seqs,label,x_len,keys,epoch = next(train_yield)\n","# writer.add_graph(model, (seqs,))\n","\n","# 准备迭代器\n","train_yield = batch_yield(train_chars,train_labels,parameter)\n","\n","# 开始训练\n","loss_cal = []\n","min_loss = float('inf')\n","num = 0 # 用于中间loss查看\n","if os.path.exists('model-transformerEncoder.h5'):\n","  print('model-transformerEncoder.h5 exist!')\n","else:\n","  with writer:\n","      while 1:\n","          seqs,label,x_len,keys,epoch = next(train_yield)\n","          if not keys:\n","              break\n","          num += 1\n","          out = model(seqs,x_len)\n","          loss = criterion(out, label)\n","          optimizer.zero_grad()\n","          loss.backward()\n","          torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n","          optimizer.step()\n","          loss_cal.append(loss.item())\n","          if num%100 == 0:\n","              print(loss.item())\n","          if epoch is not None:\n","              if (epoch+1)%1 == 0:\n","                  loss_cal = sum(loss_cal)/len(loss_cal)\n","                  if loss_cal < min_loss:\n","                      min_loss = loss_cal\n","                      torch.save(model.state_dict(), 'model-transformerEncoder.h5')\n","                  print('epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, \\\n","                                                        parameter['epoch'],loss_cal))\n","              writer.add_scalar('loss',loss_cal,global_step=epoch+1)\n","              loss_cal = [loss.item()]\n","  #     writer.flush()\n","      writer.close()\n","      \n","  # torch.save(model.state_dict(), 'model-cnn.h5')"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"第二次进行意图识别(文本分类)-最新版.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"601.6px","left":"1251px","top":"110.8px","width":"230px"},"toc_section_display":true,"toc_window_display":true},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"position":{"height":"478.4px","left":"1150.8px","right":"20px","top":"120px","width":"350px"},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":0}
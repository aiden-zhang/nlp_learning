函数
LR
特征
损失
贝叶斯公式
数据处理
随机分布
回归
方差
SVM
梯度
gbdt
xgboost
优化
过拟合
分类
随机森林
LDA
负采样
条件计算
核
Attention
估计
残差
参数
决策树
CART
逻辑
Bert
机器学习
极大似然
离散
对偶
Boosting
CRF
DeepFM
长文本
softmax
YouTube
归一化
特征选择
lr
kmeans
线性回归
正则
sklearn
GolVe
word2vec
AutoML
搜索
最优求解
复杂度
判别函数
条件随机场
deepFM
embedding
注意机制
DICE
RNN
feature
均匀分布
泰勒公式
特征值
矩阵分解
特征向量
ID3
剪枝
KKT
最小二乘法
LogisticRegression
RF
boosting
集成学习
LightGBM
XGBoost
attention
bn
BERT
先验概率
Bagging
马尔科夫
混合
MLE
MAP
DNN
Wide
Deep
欠拟合
deepfm
初始化
activation
unit
XDeepFm
DCN
留一法
导数
莱布尼兹法则
切线
法线
费马公式
拉格朗日中值
柯西不等式
期望
标准差
协方差
相关系数
伯努利
二项
二项分布
高斯分布
拉普拉斯
泊松
切比雪夫不等式
均值
聚类
标准化
信息熵
超平面
svm
Linear
logistic
CTR
sigmoid
激活函数
Sigmoid
L1
L2
l1
l2
非线性
回归估计
boostingtree
randomforest
GBDT
XGboost
Xgboost
MAE
MAPE
CNN
词袋模型
seq2seq
LN
FullTokenizer
LM
elmo
GPT
HMM
crf
W2V
Word2Vec
Doc2Vec
Dirichlet
beta
trick
隐藏层
Softmax
glove

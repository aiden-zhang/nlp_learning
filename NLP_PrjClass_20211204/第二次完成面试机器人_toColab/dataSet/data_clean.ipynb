{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T06:18:17.108860Z",
     "start_time": "2021-08-25T06:18:16.494896Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "data = pd.read_csv('relation_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T06:18:31.693657Z",
     "start_time": "2021-08-25T06:18:31.689667Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'一级科目到二级科目', '主科目到一级科目', '提问->答案', '知识点->提问'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data.关系)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T06:22:16.802179Z",
     "start_time": "2021-08-25T06:22:16.783578Z"
    }
   },
   "outputs": [],
   "source": [
    "question = list(data[data['关系']=='提问->答案']['实体1'])\n",
    "answer = list(data[data['关系']=='提问->答案']['实体2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T06:23:29.385607Z",
     "start_time": "2021-08-25T06:23:29.205638Z"
    }
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "q_cut = [jieba.lcut_for_search(i) for i in question]\n",
    "a_cut = [jieba.lcut_for_search(i) for i in answer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T06:26:02.977004Z",
     "start_time": "2021-08-25T06:26:02.955397Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "q_count = defaultdict(int)\n",
    "for i in q_cut:\n",
    "    for j in i:\n",
    "        q_count[j] += 1\n",
    "        \n",
    "a_count = defaultdict(int)\n",
    "for i in a_cut:\n",
    "    for j in i:\n",
    "        a_count[j] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T06:27:59.725660Z",
     "start_time": "2021-08-25T06:27:59.707962Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('q.txt','w') as f:\n",
    "    q = sorted(q_count.items(), key=lambda q_count:q_count[1], reverse=True)\n",
    "    for i in q:\n",
    "        f.write(i[0]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T07:05:23.761430Z",
     "start_time": "2021-08-25T07:05:23.738481Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('a.txt','w',encoding = 'utf-8') as f:\n",
    "    a = sorted(a_count.items(), key=lambda a_count:a_count[1], reverse=True)\n",
    "    for i in a:\n",
    "        f.write(i[0]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T08:27:36.319341Z",
     "start_time": "2021-08-25T08:27:36.293850Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T07:56:29.694009Z",
     "start_time": "2021-08-25T07:56:29.668960Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_word = [i.strip() for i in open('clean.txt','r',encoding = 'utf-8').readlines()]\n",
    "def clean(ins):\n",
    "    if '006y8m' not in ins:\n",
    "        for i in clean_word:\n",
    "            ins = ins.replace(i,'')\n",
    "    else:\n",
    "        for i in clean_word:\n",
    "            if i == '006y8m':\n",
    "                continue\n",
    "            ins = ins.replace(i,'')\n",
    "        tmp = [i for i in jieba.lcut_for_search(ins) if '006y8m' in i]\n",
    "        for i in tmp:\n",
    "            ins = ins.replace(i,'')\n",
    "    return ins\n",
    "\n",
    "data['实体2'] = data['实体2'].apply(clean)\n",
    "data['实体1'] = data['实体1'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T07:59:28.100987Z",
     "start_time": "2021-08-25T07:59:28.085394Z"
    }
   },
   "outputs": [],
   "source": [
    "# data[data['关系']=='提问->答案']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T08:03:37.675853Z",
     "start_time": "2021-08-25T08:03:37.660434Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T08:05:18.738946Z",
     "start_time": "2021-08-25T08:05:18.715341Z"
    }
   },
   "outputs": [],
   "source": [
    "question = list(data[data['关系']=='提问->答案'].实体1)\n",
    "answer = list(data[data['关系']=='提问->答案'].实体2)\n",
    "src = data[data['关系']=='提问->答案']\n",
    "src.to_csv('new.csv',index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T08:06:35.323851Z",
     "start_time": "2021-08-25T08:06:35.151141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<jpype._jclass.java.util.ArrayList at 0x1e49f4b1cc0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HanLP.segment(question[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T08:29:10.785406Z",
     "start_time": "2021-08-25T08:29:10.774352Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_ner(in_text):\n",
    "    # 创建关键词和对应标签的记录器\n",
    "    segs = HanLP.segment(in_text)\n",
    "    text = []\n",
    "    label = []\n",
    "    for ind,seg in enumerate(segs):\n",
    "        if str(seg.nature) == 'speacial':\n",
    "            tmp = list(seg.word)\n",
    "            text += tmp\n",
    "            if len(tmp) == 1:\n",
    "                label += ['S-Specialty']\n",
    "            if len(tmp) == 2:\n",
    "                label += ['B-Specialty']\n",
    "                label += ['E-Specialty']\n",
    "            if len(tmp) > 2:\n",
    "                label += ['B-Specialty']\n",
    "                label += ['I-Specialty']*(len(tmp)-2)\n",
    "                label += ['E-Specialty']\n",
    "        else:\n",
    "            text += list(seg.word)\n",
    "            label += ['O']*len(seg.word)\n",
    "    return text,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T15:40:51.482669Z",
     "start_time": "2021-08-25T15:40:51.452891Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "path = 'data/'\n",
    "data = {}\n",
    "for dir_0 in os.listdir(path):\n",
    "    data[dir_0] = {}\n",
    "    for dir_1 in os.listdir(path+dir_0) :\n",
    "        data[dir_0][dir_1.split('.')[0]] = {}\n",
    "        if dir_1.endswith('md'):\n",
    "            data[dir_0][dir_1.split('.')[0]] = []\n",
    "            f = open(path+dir_0+'/'+dir_1,'r',encoding = 'utf-8').readlines()\n",
    "            q,a = [],[]\n",
    "            a_keys = False\n",
    "            for context in f:\n",
    "                if context[0] == '#':\n",
    "                    q.append(context[2:].strip())\n",
    "                    a_keys = True\n",
    "                    continue\n",
    "                if a_keys:\n",
    "                    if context == '\\n':\n",
    "                        a_keys = False\n",
    "                        continue\n",
    "                    else:\n",
    "                        if len(a) < len(q):\n",
    "                            a.append(context)\n",
    "                        else:\n",
    "                            a[-1] += context\n",
    "            if len(q) == len(a):\n",
    "                for i in range(len(q)):\n",
    "                    data[dir_0][dir_1.split('.')[0]].append([q[i],a[i]])\n",
    "            else:\n",
    "                print('error',path+dir_0+'/'+dir_1)\n",
    "        else:\n",
    "            for dir_2 in os.listdir(path+dir_0+'/'+dir_1) :\n",
    "                if dir_2.endswith('md'):\n",
    "                    data[dir_0][dir_1.split('.')[0]][dir_2.split('.')[0]] = []\n",
    "                    f = open(path+dir_0+'/'+dir_1+'/'+dir_2,'r',encoding = 'utf-8').readlines()\n",
    "                    q,a = [],[]\n",
    "                    a_keys = False\n",
    "                    \n",
    "                    for context in f:\n",
    "                        if context[0] == '#':\n",
    "                            q.append(context[2:].strip())\n",
    "                            a_keys = True\n",
    "                            continue\n",
    "                        if a_keys:\n",
    "                            if context == '\\n':\n",
    "                                a_keys = False\n",
    "                                continue\n",
    "                            else:\n",
    "                                if len(a) < len(q):\n",
    "                                    a.append(context)\n",
    "                                else:\n",
    "                                    a[-1] += context\n",
    "                    if len(q) == len(a):\n",
    "                        for i in range(len(q)):\n",
    "                            data[dir_0][dir_1.split('.')[0]][dir_2.split('.')[0]].append([q[i],a[i]])\n",
    "                    else:\n",
    "                        print('error',path+dir_0+'/'+dir_1+'/'+dir_2)\n",
    "                else:\n",
    "                    print(path+dir_0+'/'+dir_1+'/'+dir_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T15:32:55.782297Z",
     "start_time": "2021-08-25T15:32:55.157035Z"
    }
   },
   "outputs": [],
   "source": [
    "# load special\n",
    "from pyhanlp import *\n",
    "with open('tmp/q.txt','r') as f:\n",
    "    for i in f.readlines():\n",
    "        i = i.strip()\n",
    "        CustomDictionary.add(i,'speacial')\n",
    "\n",
    "with open('tmp/a.txt','r',encoding = 'utf-8') as f:\n",
    "    for i in f.readlines():\n",
    "        i = i.strip()\n",
    "        CustomDictionary.add(i,'speacial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T15:40:54.231379Z",
     "start_time": "2021-08-25T15:40:54.217429Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_ner(in_text,name):\n",
    "    # 创建关键词和对应标签的记录器\n",
    "    segs = HanLP.segment(in_text)\n",
    "    text = []\n",
    "    label = []\n",
    "    for ind,seg in enumerate(segs):\n",
    "        if str(seg.nature) == 'speacial':\n",
    "            tmp = list(seg.word)\n",
    "            text += tmp\n",
    "            if len(tmp) == 1:\n",
    "                label += ['S-'+name]\n",
    "            if len(tmp) == 2:\n",
    "                label += ['B-'+name]\n",
    "                label += ['E-'+name]\n",
    "            if len(tmp) > 2:\n",
    "                label += ['B-'+name]\n",
    "                label += ['I-'+name]*(len(tmp)-2)\n",
    "                label += ['E-'+name]\n",
    "        else:\n",
    "            text += list(seg.word)\n",
    "            label += ['O']*len(seg.word)\n",
    "    return text,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T15:44:22.366457Z",
     "start_time": "2021-08-25T15:44:21.483371Z"
    }
   },
   "outputs": [],
   "source": [
    "f = open('tagging.txt','w',encoding = 'utf-8')\n",
    "for name in data:\n",
    "    for i in data[name]:\n",
    "        for j in data[name][i]:\n",
    "            q,a = j\n",
    "            text,label = get_ner(q,name)\n",
    "            for ind,tmp in enumerate(text):\n",
    "                if tmp in ['\\n',' '] or '\\\\' in tmp:\n",
    "                    continue\n",
    "                f.write(tmp+' '+label[ind]+'\\n')\n",
    "            text,label = get_ner(a,name)\n",
    "            for ind,tmp in enumerate(text):\n",
    "                if tmp in ['\\n',' '] or '\\\\' in tmp:\n",
    "                    continue\n",
    "                f.write(tmp+' '+label[ind]+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T15:40:47.974064Z",
     "start_time": "2021-08-25T15:40:47.955115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('机器学习', '集成学习')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name,i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tagging.txt','w',encoding = 'utf-8') as f:\n",
    "    for i in question:\n",
    "        text,label = get_ner(i)\n",
    "        for ind,i in enumerate(text):\n",
    "            f.write(i+' '+label[ind]+'\\n')\n",
    "            \n",
    "    for i in answer:\n",
    "        text,label = get_ner(i)\n",
    "        for ind,i in enumerate(text):\n",
    "            f.write(i+' '+label[ind]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T16:14:04.676268Z",
     "start_time": "2021-08-25T16:14:04.664300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3-5.3\\envs\\nlp\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('tmp/relation_new.csv')\n",
    "\n",
    "# {'一级科目到二级科目', '主科目到一级科目', '提问->答案', '知识点->提问'}\n",
    "def namechange(ins):\n",
    "    if ins == '主科目到一级科目':\n",
    "        return 'root2first'\n",
    "    if ins == '一级科目到二级科目':\n",
    "        return 'first2second'\n",
    "    if ins == '知识点->提问':\n",
    "        return 'second2question'\n",
    "\n",
    "data_left = data[data['关系'].isin(['主科目到一级科目','一级科目到二级科目','知识点->提问'])]\n",
    "data_left['关系'] = data_left['关系'].apply(namechange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T16:14:29.307993Z",
     "start_time": "2021-08-25T16:14:29.291039Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>实体1</th>\n",
       "      <th>实体2</th>\n",
       "      <th>关系</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>基础概念</td>\n",
       "      <td>AutoML</td>\n",
       "      <td>root2first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AutoML</td>\n",
       "      <td>AutoML问题构成?</td>\n",
       "      <td>second2question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AutoML</td>\n",
       "      <td>特征工程选择思路？</td>\n",
       "      <td>second2question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AutoML</td>\n",
       "      <td>模型相关的选择思路?</td>\n",
       "      <td>second2question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AutoML</td>\n",
       "      <td>常见优化算法思路？</td>\n",
       "      <td>second2question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>负采样流程？</td>\n",
       "      <td>second2question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>word2vec两种方法各自的优势?</td>\n",
       "      <td>second2question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>怎么衡量学到的embedding的好坏?</td>\n",
       "      <td>second2question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>word2vec和glove区别？</td>\n",
       "      <td>second2question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>Word2Vec</td>\n",
       "      <td>你觉得word2vec有哪些问题？</td>\n",
       "      <td>second2question</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>355 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          实体1                   实体2               关系\n",
       "0        基础概念                AutoML       root2first\n",
       "1      AutoML           AutoML问题构成?  second2question\n",
       "3      AutoML             特征工程选择思路？  second2question\n",
       "5      AutoML            模型相关的选择思路?  second2question\n",
       "7      AutoML             常见优化算法思路？  second2question\n",
       "..        ...                   ...              ...\n",
       "656  Word2Vec                负采样流程？  second2question\n",
       "658  Word2Vec    word2vec两种方法各自的优势?  second2question\n",
       "660  Word2Vec  怎么衡量学到的embedding的好坏?  second2question\n",
       "662  Word2Vec     word2vec和glove区别？  second2question\n",
       "664  Word2Vec     你觉得word2vec有哪些问题？  second2question\n",
       "\n",
       "[355 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T15:56:20.159774Z",
     "start_time": "2021-08-25T15:56:20.148814Z"
    }
   },
   "outputs": [],
   "source": [
    "data_new = data[data['关系'] == '提问->答案']\n",
    "data_new_q = list(data_new.实体1)\n",
    "data_new_a = list(data_new.实体2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T16:07:01.488449Z",
     "start_time": "2021-08-25T16:07:00.886176Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_f(in_text):\n",
    "    segs = HanLP.segment(in_text)\n",
    "    text = []\n",
    "    for ind,seg in enumerate(segs):\n",
    "        if str(seg.nature) == 'speacial':\n",
    "            text.append(seg.word)\n",
    "    return text\n",
    "\n",
    "data_new_f2q = []\n",
    "for i in data_new_q:\n",
    "    f = get_f(i)\n",
    "    for f_s in f:\n",
    "        data_new_f2q.append([i,f_s])\n",
    "        \n",
    "data_new_a2f = []\n",
    "for answer in data_new_a:\n",
    "    for answer_single in answer.split('\\n'):\n",
    "        answer_single = answer_single.replace(' ','').replace('-','')\n",
    "        f = get_f(answer_single)\n",
    "        for f_s in f:\n",
    "            data_new_a2f.append([answer_single,f_s])\n",
    "            \n",
    "data_new_q2a = []\n",
    "for ind,answer in enumerate(data_new_a):\n",
    "    for answer_single in answer.split('\\n'):\n",
    "        answer_single = answer_single.replace(' ','').replace('-','')\n",
    "        if answer_single == '':\n",
    "            continue\n",
    "        data_new_q2a.append([data_new_q[ind],answer_single])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T16:20:03.115576Z",
     "start_time": "2021-08-25T16:20:03.092036Z"
    }
   },
   "outputs": [],
   "source": [
    "q2a = pd.DataFrame(data_new_q2a)\n",
    "q2a.columns = ['实体1','实体2']\n",
    "q2a['关系'] = 'question2answer'\n",
    "\n",
    "question2feature = pd.DataFrame(data_new_f2q)\n",
    "question2feature.columns = ['实体1','实体2']\n",
    "question2feature['关系'] = 'question2feature'\n",
    "\n",
    "answer2feature = pd.DataFrame(data_new_a2f)\n",
    "answer2feature.columns = ['实体1','实体2']\n",
    "answer2feature['关系'] = 'answer2feature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T16:21:28.201364Z",
     "start_time": "2021-08-25T16:21:28.191418Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1390, 421, 2099, 355)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(q2a),len(question2feature),len(answer2feature),len(data_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T16:22:03.518985Z",
     "start_time": "2021-08-25T16:22:03.505022Z"
    }
   },
   "outputs": [],
   "source": [
    "new = q2a.append(question2feature).append(answer2feature).append(data_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T16:22:39.795953Z",
     "start_time": "2021-08-25T16:22:39.771004Z"
    }
   },
   "outputs": [],
   "source": [
    "new.to_csv('data_src.csv',index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T16:27:01.226723Z",
     "start_time": "2021-08-25T16:27:00.711649Z"
    }
   },
   "outputs": [],
   "source": [
    "# {'answer2feature',\n",
    "#  'first2second',\n",
    "#  'question2answer',\n",
    "#  'question2feature',\n",
    "#  'root2first',\n",
    "#  'second2question'}\n",
    "entity = []\n",
    "for i in range(len(new)):\n",
    "    i = new.iloc[i]\n",
    "    e1 = i.实体1\n",
    "    e2 = i.实体2\n",
    "    r = i.关系.split('2')\n",
    "    entity.append([hash(e1),e1,r[0]])\n",
    "    entity.append([hash(e2),e2,r[1]])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T16:29:19.927217Z",
     "start_time": "2021-08-25T16:29:19.909266Z"
    }
   },
   "outputs": [],
   "source": [
    "entity = pd.DataFrame(entity)\n",
    "entity.columns = [':ID','name',':LABEL']\n",
    "entity = entity.drop_duplicates(subset=['name'],keep='first')\n",
    "entity.to_csv('entity.csv',index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T16:35:16.023472Z",
     "start_time": "2021-08-25T16:35:15.999552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           实体1                          实体2               关系\n",
      "0  AutoML问题构成?                         特征选择  question2answer\n",
      "1  AutoML问题构成?                         模型选择  question2answer\n",
      "2  AutoML问题构成?                         算法选择  question2answer\n",
      "3    特征工程选择思路？                     有监督的特征选择  question2answer\n",
      "4    特征工程选择思路？  基于模型，lr的系数，树模型的importance等等  question2answer\n",
      "5    特征工程选择思路？                  基于选择，前项后项选择  question2answer\n",
      "6    特征工程选择思路？                     无监督的特征选择  question2answer\n",
      "7    特征工程选择思路？           基于统计信息的，熵、相关性、KL系数  question2answer\n",
      "8    特征工程选择思路？      基于方差，因子分解，PCA主成分分享，方差系数  question2answer\n",
      "9   模型相关的选择思路?                         模型选择  question2answer\n"
     ]
    }
   ],
   "source": [
    "def do(ins):\n",
    "    return hash(ins)\n",
    "new = pd.read_csv('data_src.csv')\n",
    "new['name'] = new['关系']\n",
    "new.columns = [':START_ID',':END_ID',':TYPE','name']\n",
    "new = new[[':START_ID','name',':END_ID',':TYPE']]\n",
    "new[':START_ID'] = new[':START_ID'].apply(do)\n",
    "new[':END_ID'] = new[':END_ID'].apply(do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T16:36:15.323600Z",
     "start_time": "2021-08-25T16:36:15.298276Z"
    }
   },
   "outputs": [],
   "source": [
    "new.to_csv('relation.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

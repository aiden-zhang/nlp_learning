{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75utbFZCtFso"
   },
   "source": [
    "#注意:\n",
    "此文件已在colab上验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUPEpIbks9HM"
   },
   "source": [
    "#配置colab环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38681,
     "status": "ok",
     "timestamp": 1641477942057,
     "user": {
      "displayName": "aiden zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00038965460335847869"
     },
     "user_tz": -480
    },
    "id": "rbxUx10Gs8Gn",
    "outputId": "938f5aa5-0c1f-4d29-861b-2e9301e5c022"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.4 MB 14.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 66.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 679 kB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 61.9 MB/s \n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[K     |████████████████████████████████| 596 kB 81.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
      "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.15.0\n",
      "Collecting pytorch-crf\n",
      "  Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n",
      "Installing collected packages: pytorch-crf\n",
      "Successfully installed pytorch-crf-0.7.2\n",
      "path: /content/gdrive/MyDrive/第二次完成面试机器人_toColab/src/grade/\n",
      "/content/gdrive/MyDrive/第二次完成面试机器人_toColab/src/grade\n",
      "grade.h5       意图识别推理及评测.ipynb\t\t  打分算法-基于文本分类.ipynb\n",
      "parameter.pkl  意图识别（文本分类）-最新版.ipynb  打分算法-推理.ipynb\n"
     ]
    }
   ],
   "source": [
    "#colab中运行jupyter文件的步骤：\n",
    "# 1.挂载云盘\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "# 2.安装需要的软件\n",
    "!pip3 install transformers\n",
    "!pip3 install pytorch-crf\n",
    "\n",
    "import os\n",
    "def get_root_dir():\n",
    "    if os.path.exists('/content/gdrive/MyDrive/第二次完成面试机器人_toColab/src/grade'):\n",
    "        return '/content/gdrive/MyDrive/第二次完成面试机器人_toColab/src/grade/'\n",
    "    else:\n",
    "        return './' #在本地\n",
    "\n",
    "# 3.调用系统命令，切换到对应工程路径，相当于cd，但是直接!cd是不行的\n",
    "print(\"path:\",get_root_dir())\n",
    "os.chdir(get_root_dir())\n",
    "\n",
    "# 4.再次确认路径\n",
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T06:28:46.051464Z",
     "start_time": "2021-08-26T06:28:46.029499Z"
    },
    "executionInfo": {
     "elapsed": 473,
     "status": "ok",
     "timestamp": 1641480136688,
     "user": {
      "displayName": "aiden zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00038965460335847869"
     },
     "user_tz": -480
    },
    "id": "oW-IYiUCs3ow"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F # pytorch 激活函数的类\n",
    "from torch import nn,optim # 构建模型和优化器\n",
    "import torch\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "import jieba\n",
    "import pdb\n",
    "\n",
    "class Grade(nn.Module):\n",
    "    def __init__(self, parameter):\n",
    "        super(Grade, self).__init__()\n",
    "        embedding_dim = parameter['embedding_dim']\n",
    "        hidden_size = parameter['hidden_size']\n",
    "        num_layers = parameter['num_layers']\n",
    "        dropout = parameter['dropout']\n",
    "        word_size = parameter['word_size']\n",
    "        self.embedding = nn.Embedding(word_size, embedding_dim, padding_idx=0)\n",
    "        \n",
    "        self.lstm_q = nn.LSTM(embedding_dim, hidden_size, num_layers, bidirectional=True, batch_first=True, dropout=dropout)\n",
    "\n",
    "        self.lstm_a = nn.LSTM(embedding_dim, hidden_size, num_layers, bidirectional=True, batch_first=True, dropout=dropout)\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        \n",
    "    def forward(self, q, a1,a2 = None):\n",
    "        q_emd = self.embedding(q)\n",
    "        q_emd,(h, c)= self.lstm_q(q_emd)\n",
    "        q_emd = torch.max(q_emd,1)[0]\n",
    "\n",
    "        a1_emd = self.embedding(a1)\n",
    "        a1_emd,(h, c)= self.lstm_a(a1_emd)\n",
    "        a1_emd = torch.max(a1_emd,1)[0]\n",
    "        if a2 is not None:\n",
    "            a2_emd = self.embedding(a2)\n",
    "            a2_emd,(h, c)= self.lstm_a(a2_emd)\n",
    "            a2_emd = torch.max(a2_emd,1)[0]\n",
    "            return q_emd,a1_emd,a2_emd\n",
    "        return F.cosine_similarity(q_emd,a1_emd,1,1e-8)\n",
    "\n",
    "\n",
    "    \n",
    "def list2torch(a):\n",
    "    return torch.from_numpy(np.array(a)).long().to(parameter['cuda'])\n",
    "\n",
    "def predict(model,parameter,q,a):\n",
    "    #pdb.set_trace()\n",
    "    q = list(q)\n",
    "    a = list(a)\n",
    "    q_cut = []\n",
    "    for i in q:\n",
    "        if i in parameter['word2id']:\n",
    "            q_cut.append(parameter['word2id'][i])\n",
    "        else:\n",
    "            q_cut.append(parameter['word2id']['<UNK>'])\n",
    "    a_cut = []\n",
    "    for i in a:\n",
    "        if i in parameter['word2id']:\n",
    "            a_cut.append(parameter['word2id'][i])\n",
    "        else:\n",
    "            a_cut.append(parameter['word2id']['<UNK>'])\n",
    "    print(q_cut,a_cut)\n",
    "    q_cut,a_cut = [q_cut[:parameter['max_len']]],[a_cut[:parameter['max_len']]]\n",
    "    prob = model(list2torch(q_cut),list2torch(a_cut))\n",
    "    print(prob)\n",
    "    return prob.cpu().item()\n",
    "\n",
    "def load_model(root_path = './'):\n",
    "    parameter = pk.load(open(root_path+'parameter.pkl','rb'))\n",
    "    model = Grade(parameter).to(parameter['cuda'])\n",
    "    model.load_state_dict(torch.load(root_path+'grade.h5'))\n",
    "    model.eval()\n",
    "    return model,parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T06:28:47.028547Z",
     "start_time": "2021-08-26T06:28:46.974685Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1641480138746,
     "user": {
      "displayName": "aiden zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00038965460335847869"
     },
     "user_tz": -480
    },
    "id": "HMTinUQ7s3o1",
    "outputId": "bbf89612-5977-45c3-e7fb-8e2dcc6382e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 14, 21, 22, 15, 16, 23, 24, 25] [30, 31, 50, 51, 52, 53, 29, 32, 54, 55, 56, 57, 58, 55, 59, 7, 35, 36]\n",
      "tensor([0.6987], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6986643671989441"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,parameter = load_model()\n",
    "q = '特征工程选择思路？'\n",
    "a = '基于统计信息的，熵、相关性、KL系数'\n",
    "prob = predict(model,parameter,q,a)\n",
    "prob"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "打分算法-推理.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

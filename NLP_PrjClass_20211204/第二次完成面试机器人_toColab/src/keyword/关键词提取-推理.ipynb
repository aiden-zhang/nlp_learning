{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T17:26:36.984900Z",
     "start_time": "2021-08-26T17:26:32.564217Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import WEIGHTS_NAME, BertConfig,get_linear_schedule_with_warmup,AdamW, BertTokenizer\n",
    "from transformers import BertModel,BertPreTrainedModel\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "import torch.nn.functional as F # pytorch 激活函数的类\n",
    "from torch import nn,optim # 构建模型和优化器\n",
    "from torchcrf import CRF\n",
    "import pickle as pk\n",
    "\n",
    "\n",
    "class bert_crf(BertPreTrainedModel):\n",
    "    def __init__(self, config,parameter):\n",
    "        super(bert_crf, self).__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        embedding_dim = parameter['d_model']\n",
    "        output_size = parameter['output_size']\n",
    "        self.fc = nn.Linear(embedding_dim, output_size)\n",
    "        self.init_weights()\n",
    "        \n",
    "        self.crf = CRF(output_size,batch_first=True)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None,labels=None):\n",
    "        outputs = self.bert(input_ids = input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids)\n",
    "        sequence_output = outputs[0]\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.fc(sequence_output)\n",
    "        return logits\n",
    "    \n",
    "config_class, bert_crf, tokenizer_class = BertConfig, bert_crf, BertTokenizer\n",
    "config = config_class.from_pretrained(\"prev_trained_model\")\n",
    "tokenizer = tokenizer_class.from_pretrained(\"prev_trained_model\")\n",
    "\n",
    "\n",
    "def load_model(root_path = './'):\n",
    "    parameter = pk.load(open(root_path+'parameter.pkl','rb'))\n",
    "    #print(parameter)\n",
    "    #因为colab使用GPU训练的，这里要改成cpu在本地进行推理\n",
    "    parameter['device']='cpu'\n",
    "    model = bert_crf(config,parameter).to(parameter['device'])\n",
    "    \n",
    "    model.load_state_dict(torch.load(root_path+'bert_crf.h5',map_location='cpu'))\n",
    "    model.eval()\n",
    "    return model,parameter\n",
    "\n",
    "def list2torch(ins):\n",
    "    return torch.from_numpy(np.array(ins)).long().to(parameter['device'])\n",
    "\n",
    "def keyword_predict(input):\n",
    "    input = list(input)\n",
    "    input_id = tokenizer.convert_tokens_to_ids(input)\n",
    "    predict = model.crf.decode(model(list2torch([input_id])))[0]\n",
    "    predict = itemgetter(*predict)(parameter['ind2key'])\n",
    "    keys_list = []\n",
    "    for ind,i in enumerate(predict):\n",
    "        if i == 'O':\n",
    "            continue\n",
    "        if i[0] == 'S':\n",
    "            if not(len(keys_list) == 0 or keys_list[-1][-1]):\n",
    "                del keys_list[-1]\n",
    "            keys_list.append([input[ind],[i],[ind],True])\n",
    "            continue\n",
    "        if i[0] == 'B':\n",
    "            if not(len(keys_list) == 0 or keys_list[-1][-1]):\n",
    "                del keys_list[-1]\n",
    "            keys_list.append([input[ind],[i],[ind],False])\n",
    "            continue\n",
    "        if i[0] == 'I':\n",
    "            if len(keys_list) > 0 and not keys_list[-1][-1] and \\\n",
    "            keys_list[-1][1][0].split('-')[1] == i.split('-')[1]:\n",
    "                keys_list[-1][0] += input[ind]\n",
    "                keys_list[-1][1] += [i]\n",
    "                keys_list[-1][2] += [ind]\n",
    "            else:\n",
    "                del keys_list[-1]\n",
    "            continue\n",
    "        if i[0] == 'E':\n",
    "            if len(keys_list) > 0 and not keys_list[-1][-1] and \\\n",
    "            keys_list[-1][1][0].split('-')[1] == i.split('-')[1]:\n",
    "                keys_list[-1][0] += input[ind]\n",
    "                keys_list[-1][1] += [i]\n",
    "                keys_list[-1][2] += [ind]\n",
    "                keys_list[-1][3] = True\n",
    "            else:\n",
    "                del keys_list[-1]\n",
    "            continue\n",
    "#     print(keys_list)\n",
    "    keys_list = [i[0] for i in keys_list]\n",
    "    return keys_list\n",
    "\n",
    "model,parameter = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T17:26:38.768100Z",
     "start_time": "2021-08-26T17:26:38.563047Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\torchcrf\\__init__.py:305: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorCompare.cpp:255.)\n",
      "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['分类', '判别', '不确定性']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = '如果明明知道隐变量在此次分类的过程中起到非常巨大作用的情况下，判别模型对隐变量的学习往往通过人为构造，更加不确定性'\n",
    "res = keyword_predict(test_sentence)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

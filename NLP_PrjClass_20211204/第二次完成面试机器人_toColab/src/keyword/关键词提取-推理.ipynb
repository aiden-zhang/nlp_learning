{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOd0DniFhnj3"
   },
   "source": [
    "# 注意:\n",
    "此代码已经过colab验证，其实就是ner模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIOC0RjIgWUx"
   },
   "source": [
    "配置colab环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 56449,
     "status": "ok",
     "timestamp": 1641306945168,
     "user": {
      "displayName": "aiden zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00038965460335847869"
     },
     "user_tz": -480
    },
    "id": "IHCSVGGIgUtW",
    "outputId": "a7cfae17-f621-4609-d513-5f1794f2f3c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.4 MB 7.0 MB/s \n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 599 kB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 50.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[K     |████████████████████████████████| 596 kB 65.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 51.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
      "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.15.0\n",
      "Collecting pytorch-crf\n",
      "  Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n",
      "Installing collected packages: pytorch-crf\n",
      "Successfully installed pytorch-crf-0.7.2\n",
      "path: /content/gdrive/MyDrive/第二次完成面试机器人_toColab/src/keyword/\n",
      "/content/gdrive/MyDrive/第二次完成面试机器人_toColab/src/keyword\n",
      "bert_crf.h5    prev_trained_model  关键词提取-推理.ipynb\n",
      "parameter.pkl  关键词提取.ipynb    测试模型.ipynb\n"
     ]
    }
   ],
   "source": [
    "#colab中运行jupyter文件的步骤：\n",
    "# 1.挂载云盘\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "# 2.安装需要的软件\n",
    "!pip3 install transformers\n",
    "!pip3 install pytorch-crf\n",
    "\n",
    "import os\n",
    "def get_root_dir():\n",
    "    if os.path.exists('/content/gdrive/MyDrive/第二次完成面试机器人_toColab/src/keyword'):\n",
    "        return '/content/gdrive/MyDrive/第二次完成面试机器人_toColab/src/keyword/'\n",
    "    else:\n",
    "        return './' #在本地\n",
    "\n",
    "# 3.调用系统命令，切换到对应工程路径，相当于cd，但是直接!cd是不行的\n",
    "print(\"path:\",get_root_dir())\n",
    "os.chdir(get_root_dir())\n",
    "\n",
    "# 4.再次确认路径\n",
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T17:26:36.984900Z",
     "start_time": "2021-08-26T17:26:32.564217Z"
    },
    "executionInfo": {
     "elapsed": 8512,
     "status": "ok",
     "timestamp": 1641307064352,
     "user": {
      "displayName": "aiden zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00038965460335847869"
     },
     "user_tz": -480
    },
    "id": "b3xkg0qxgNyX"
   },
   "outputs": [],
   "source": [
    "from transformers import WEIGHTS_NAME, BertConfig,get_linear_schedule_with_warmup,AdamW, BertTokenizer\n",
    "from transformers import BertModel,BertPreTrainedModel\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from operator import itemgetter\n",
    "import torch.nn.functional as F # pytorch 激活函数的类\n",
    "from torch import nn,optim # 构建模型和优化器\n",
    "from torchcrf import CRF\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "\n",
    "class bert_crf(BertPreTrainedModel):\n",
    "    def __init__(self, config,parameter):\n",
    "        super(bert_crf, self).__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        embedding_dim = parameter['d_model']\n",
    "        output_size = parameter['output_size']\n",
    "        self.fc = nn.Linear(embedding_dim, output_size)\n",
    "        self.init_weights()\n",
    "        \n",
    "        self.crf = CRF(output_size,batch_first=True)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None,labels=None):\n",
    "        outputs = self.bert(input_ids = input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids)\n",
    "        sequence_output = outputs[0]\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.fc(sequence_output)\n",
    "        return logits\n",
    "    \n",
    "config_class, bert_crf, tokenizer_class = BertConfig, bert_crf, BertTokenizer\n",
    "config = config_class.from_pretrained(\"prev_trained_model\")\n",
    "tokenizer = tokenizer_class.from_pretrained(\"prev_trained_model\")\n",
    "\n",
    "\n",
    "def load_model(root_path = './'):\n",
    "    parameter = pk.load(open(root_path+'parameter.pkl','rb'))\n",
    "    model = bert_crf(config,parameter).to(parameter['device'])\n",
    "    model.load_state_dict(torch.load(root_path+'bert_crf.h5'))\n",
    "    model.eval()\n",
    "    return model,parameter\n",
    "\n",
    "def list2torch(ins):\n",
    "    return torch.from_numpy(np.array(ins)).long().to(parameter['device'])\n",
    "\n",
    "def keyword_predict(input):\n",
    "    input = list(input)\n",
    "    input_id = tokenizer.convert_tokens_to_ids(input)\n",
    "    predict = model.crf.decode(model(list2torch([input_id])))[0]\n",
    "    predict = itemgetter(*predict)(parameter['ind2key'])\n",
    "    keys_list = []\n",
    "    for ind,i in enumerate(predict):\n",
    "        if i == 'O':\n",
    "            continue\n",
    "        if i[0] == 'S':\n",
    "            if not(len(keys_list) == 0 or keys_list[-1][-1]):\n",
    "                del keys_list[-1]\n",
    "            keys_list.append([input[ind],[i],[ind],True])\n",
    "            continue\n",
    "        if i[0] == 'B':\n",
    "            if not(len(keys_list) == 0 or keys_list[-1][-1]):\n",
    "                del keys_list[-1]\n",
    "            keys_list.append([input[ind],[i],[ind],False])\n",
    "            continue\n",
    "        if i[0] == 'I':\n",
    "            if len(keys_list) > 0 and not keys_list[-1][-1] and \\\n",
    "            keys_list[-1][1][0].split('-')[1] == i.split('-')[1]:\n",
    "                keys_list[-1][0] += input[ind]\n",
    "                keys_list[-1][1] += [i]\n",
    "                keys_list[-1][2] += [ind]\n",
    "            else:\n",
    "                del keys_list[-1]\n",
    "            continue\n",
    "        if i[0] == 'E':\n",
    "            if len(keys_list) > 0 and not keys_list[-1][-1] and \\\n",
    "            keys_list[-1][1][0].split('-')[1] == i.split('-')[1]:\n",
    "                keys_list[-1][0] += input[ind]\n",
    "                keys_list[-1][1] += [i]\n",
    "                keys_list[-1][2] += [ind]\n",
    "                keys_list[-1][3] = True\n",
    "            else:\n",
    "                del keys_list[-1]\n",
    "            continue\n",
    "#     print(keys_list)\n",
    "    keys_list = [i[0] for i in keys_list]\n",
    "    return keys_list\n",
    "\n",
    "model,parameter = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-26T17:26:38.768100Z",
     "start_time": "2021-08-26T17:26:38.563047Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 417,
     "status": "ok",
     "timestamp": 1641307068648,
     "user": {
      "displayName": "aiden zhang",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "00038965460335847869"
     },
     "user_tz": -480
    },
    "id": "ompfHr4cgNyd",
    "outputId": "9ddce29a-8504-4125-a12c-38763789be99"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchcrf/__init__.py:305: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ../aten/src/ATen/native/TensorCompare.cpp:328.)\n",
      "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['分类', '判别', '不确定性']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = '如果明明知道隐变量在此次分类的过程中起到非常巨大作用的情况下，判别模型对隐变量的学习往往通过人为构造，更加不确定性'\n",
    "res = keyword_predict(test_sentence)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TSIqPdfHhlPM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "关键词提取-推理.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

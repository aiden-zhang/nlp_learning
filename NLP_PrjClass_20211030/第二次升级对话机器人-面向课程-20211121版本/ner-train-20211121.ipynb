{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-21T02:39:28.313989Z",
     "start_time": "2021-11-21T02:39:27.267475Z"
    }
   },
   "source": [
    "# 数据准备+预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-21T03:08:50.583621Z",
     "start_time": "2021-11-21T03:08:49.493005Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import gensim\n",
    "import os\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    torch.cuda.set_device(0)\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "[x_intent,y_intent,x_ner,y_ner] = pk.load(open('data/data-intent1-ner.pkl','rb'))\n",
    "train_data = [(x_ner[i],y_ner[i]) for i in range(len(x_ner))]\n",
    "vocab = set([j for i in x_ner for j in i])\n",
    "vocab = dict(zip(vocab,range(1,len(vocab)+1)))\n",
    "vocab['<PAD>'] = 0\n",
    "vocab['<UNK>'] = len(vocab)\n",
    "tag2label = ['O']+list(set([j for i in y_ner for j in i]) - set('O'))\n",
    "tag2label = dict(zip(tag2label,range(len(tag2label))))\n",
    "\n",
    "# 准备好模型的参数\n",
    "parameter = {\n",
    "    'min_count_word':1,\n",
    "    'batch_size':32,\n",
    "    'epoch':10,\n",
    "    'hid_dim':300,\n",
    "    'dropout':0.5,\n",
    "    'lr':0.001,\n",
    "    'tag2label':tag2label,\n",
    "    'num_tags':len(tag2label),\n",
    "    'd_model':768,\n",
    "    'shuffle':True,\n",
    "    'vocab':None,\n",
    "    'model_path':None,\n",
    "    'num_unknow':0,\n",
    "    'n_layers':2,\n",
    "    'device':device,\n",
    "}\n",
    "out_path = 'model/'\n",
    "os.mkdir(out_path) if not os.path.exists(out_path) else 1\n",
    "model_path = os.path.join(out_path, \"ner/\")\n",
    "os.mkdir(model_path) if not os.path.exists(model_path) else 1\n",
    "parameter['vocab'] = vocab\n",
    "parameter['vocab_size'] = len(vocab)\n",
    "parameter['model_path'] = model_path\n",
    "\n",
    "def batch_yield(data,parameter,shuffle = True):\n",
    "    def list2torch(ins):\n",
    "        return torch.from_numpy(np.array(ins))\n",
    "\n",
    "    def seq2id(seq, vocab):\n",
    "        sentence_id = []\n",
    "        for word in seq:\n",
    "            if word not in vocab:\n",
    "                word = '<UNK>'\n",
    "            sentence_id.append(vocab[word])\n",
    "        return sentence_id\n",
    "    # 构建一个迭代器，获取相应的seqs（index型）和label，按照batch_size提取\n",
    "    if shuffle:\n",
    "        random.shuffle(data)\n",
    "    seqs,labels = [],[]\n",
    "    for (seq,label) in tqdm(data):\n",
    "        seq = seq2id(seq,parameter['vocab'])\n",
    "        label = [parameter['tag2label'][label_] for label_ in label]\n",
    "        if len(seqs) == parameter['batch_size']:\n",
    "            seq_len_list = [len(i) for i in seqs]\n",
    "            max_len = max(seq_len_list)\n",
    "            seqs = [i+[0]*(max_len-len(i)) for i in seqs]\n",
    "            labels = [i+[0]*(max_len-len(i)) for i in labels]\n",
    "            yield list2torch(seqs),list2torch(labels),False\n",
    "            seqs,labels = [],[]\n",
    "        seqs.append(seq)\n",
    "        labels.append(label)\n",
    "    if len(seqs) != 0:\n",
    "        seq_len_list = [len(i) for i in seqs]\n",
    "        max_len = max(seq_len_list)\n",
    "        seqs = [i+[0]*(max_len-len(i)) for i in seqs]\n",
    "        labels = [i+[0]*(max_len-len(i)) for i in labels]\n",
    "        yield list2torch(seqs), list2torch(labels),True\n",
    "\n",
    "pk.dump(parameter,open(parameter['model_path']+'/parameter.pkl','wb'))\n",
    "            \n",
    "# data = batch_yield(train_data,parameter)\n",
    "# seqs, labels,keys = next(data)\n",
    "# seqs.shape,labels.shape,seqs[:2],labels[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-21T03:17:04.417071Z",
     "start_time": "2021-11-21T03:17:04.407099Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'I-km1': 1,\n",
       " 'E-tag': 2,\n",
       " 'I-kg': 3,\n",
       " 'E-title': 4,\n",
       " 'E-kg': 5,\n",
       " 'B-tag': 6,\n",
       " 'E-class': 7,\n",
       " 'E-author': 8,\n",
       " 'B-km2': 9,\n",
       " 'I-class': 10,\n",
       " 'I-tag': 11,\n",
       " 'B-km1': 12,\n",
       " 'S-author': 13,\n",
       " 'S-class': 14,\n",
       " 'S-kg': 15,\n",
       " 'E-km2': 16,\n",
       " 'B-author': 17,\n",
       " 'B-kg': 18,\n",
       " 'B-class': 19,\n",
       " 'I-km2': 20,\n",
       " 'I-title': 21,\n",
       " 'S-title': 22,\n",
       " 'I-author': 23,\n",
       " 'E-km1': 24,\n",
       " 'B-title': 25}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter['tag2label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型构建及模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-21T03:16:45.719413Z",
     "start_time": "2021-11-21T03:08:57.842738Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/42534 [00:00<?, ?it/s]D:\\Anaconda3\\lib\\site-packages\\torchcrf\\__init__.py:249: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorCompare.cpp:255.)\n",
      "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 42534/42534 [11:33<00:00, 61.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/10], Loss: 73.6042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 42534/42534 [10:51<00:00, 65.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [2/10], Loss: 5.3350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 42534/42534 [10:57<00:00, 64.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [3/10], Loss: 2.3925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 42534/42534 [12:36<00:00, 56.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [4/10], Loss: 1.3998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 42534/42534 [12:51<00:00, 55.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [5/10], Loss: 0.9673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 42534/42534 [11:41<00:00, 60.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [6/10], Loss: 0.7036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 42534/42534 [12:03<00:00, 58.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [7/10], Loss: 0.5708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 42534/42534 [11:17<00:00, 62.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [8/10], Loss: 0.4540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 42534/42534 [10:57<00:00, 64.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [9/10], Loss: 0.3770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 42534/42534 [10:42<00:00, 66.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [10/10], Loss: 0.3374\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F # pytorch 激活函数的类\n",
    "from torch import nn,optim # 构建模型和优化器\n",
    "from torchcrf import CRF\n",
    "\n",
    "\n",
    "# 构建基于bilstm+crf实现ner\n",
    "class bilstm_crf(nn.Module):\n",
    "    def __init__(self, parameter):\n",
    "        super(bilstm_crf, self).__init__()\n",
    "        vocab_size = parameter['vocab_size']\n",
    "        embedding_dim = parameter['d_model']\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "\n",
    "        hidden_size = parameter['hid_dim']\n",
    "        num_layers = parameter['n_layers']\n",
    "        dropout = parameter['dropout']\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, bidirectional=True, batch_first=True, dropout=dropout)\n",
    "\n",
    "        output_size = parameter['num_tags']\n",
    "        self.fc = nn.Linear(hidden_size*2, output_size)\n",
    "        \n",
    "        self.crf = CRF(output_size,batch_first=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out,(h, c)= self.lstm(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "import os\n",
    "import shutil\n",
    "import pickle as pk\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "# 构建模型\n",
    "model = bilstm_crf(parameter).to(parameter['device'])\n",
    "\n",
    "# 确定训练模式\n",
    "model.train()\n",
    "\n",
    "# 确定优化器和损失\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.00005, momentum=0.95, nesterov=True)\n",
    "# optimizer = torch.optim.Adam(model.parameters(),lr = parameter['lr'], \\\n",
    "#                              weight_decay = 0.01)\n",
    "\n",
    "# 准备学习率策略\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)\n",
    "\n",
    "\n",
    "# 开始训练\n",
    "loss_cal = []\n",
    "min_loss = float('inf')\n",
    "for epoch in range(parameter['epoch']):\n",
    "    # 迭代器重置\n",
    "    train_yield = batch_yield(train_data,parameter)\n",
    "    while 1:\n",
    "        inputs,targets,keys = next(train_yield)\n",
    "        out = model(inputs.long().to(parameter['device']))\n",
    "        loss = -model.crf(out,targets.long().to(parameter['device']))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_cal.append(loss.item())\n",
    "        if keys:\n",
    "            break\n",
    "    loss_cal = sum(loss_cal)/len(loss_cal)\n",
    "    if loss_cal < min_loss:\n",
    "        min_loss = loss_cal\n",
    "        torch.save(model.state_dict(), parameter['model_path']+'/bilstm_crf.h5')\n",
    "        print('epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, \\\n",
    "                                                       parameter['epoch'],loss_cal))\n",
    "    loss_cal = [loss.item()]\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
